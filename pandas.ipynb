{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a csv from a jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from IPython.display import HTML\n",
    "import base64  \n",
    "import pandas as pd  \n",
    "\n",
    "def create_download_link( df, title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    csv = df.to_csv(index =False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "create_download_link(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first project is an introduction to ``pandas``, the most popular data-management tool in Python.\n",
    "\n",
    "Pandas is our swiss knife when it comes to Data Analysis/Science in Python. We use it to:\n",
    "\n",
    "- **Load/dump read/write data**: to and from different formats (CSV, XML, HTML, Excel, JSON, even from the Internet)\n",
    "- **Analyze data**: perform statistical analysis, query the data, find inconsistencies, etc\n",
    "- **Data cleaning**: finding missing values, duplicate data, invalid or broken values, etc\n",
    "- **Visualizations**: with support from ``matplotlib``, we can quickly visualize data\n",
    "- **Data Wrangling/Munging**: a non-so-scientific term that involves data handling: merging multiple data sources, creating derived representations, grouping data, etc.\n",
    "\n",
    "In this project you will not learn much about how to use Pandas, but you'll see it in action. So, don't worry if you don't feel comfortable \"doing\" what's shown here, it'll all be explained in the following projects.\n",
    "\n",
    "Let's get started! Switch to the next page and start your lab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you started your lab? If you haven't yet, please go ahead and start the lab. Also, execute the first couple of cells:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"s&p500.csv\", index_col='Date', parse_dates=True)\n",
    "df.head()\n",
    "df.tail()\n",
    "```\n",
    "\n",
    "We first start importing the ``pandas`` library, and as we use it SO much, we like to create a short alias ``pd``. We then load the sample dataset for this project: the S&P500 index from 2017 to 2022.\n",
    "\n",
    "We load the data using the ``read_csv`` method. Throughout these labs, you'll see that pandas can load data from a lot of different formats, and methods are usually ``read_XXX``; for example: ``read_json``, ``read_excel``, ``read_xml``, etc.\n",
    "\n",
    "We've now loaded the data contained in the CSV into the variable ``df``: a DataFrame. DataFrames are the key data structure used by Pandas and you'll see A LOT of them in the following projects; so, don't worry too much about it for now.\n",
    "\n",
    "Then, we take a few quick peeks at the data with the ``.head()`` and ``.tail()`` methods. This is because pandas is prepared to handle MILLIONS of rows (or even more). So we don't usually \"print\" the whole data, we just take quick peeks at it.\n",
    "\n",
    "The ``.head()`` method shows the first 5 rows, the ``.tail()`` method shows the last 5 rows. You can immediately see that the DataFrame looks pretty much like an Excel table. It contains an index, which is the date of the reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"SP500 index 2017 2022.csv\", index_col='Date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis phase is of course dependant of the task at hand, and the data at hand. This is just an example of the capabilities of pandas.\n",
    "\n",
    "We start by using the ``.describe()`` method, that provides quick summary statistics of the whole DataFrame. We have information like the ``mean`` (the average), ``max``, etc.\n",
    "\n",
    "We can also get specific information for a single column: ``df['Close'].min()`` or ``df['Close'].max()``. Oh, by the way, you've just seen how to perform \"single column selection\": ``df['Close'].head()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single column statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single column selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas makes it simple to visualize data with the ``.plot()`` method. In reality, ``.plot()`` is just a wrapper around ``matplotlib``, the de-facto plotting library for Python.\n",
    "\n",
    "As you can see, plotting a column is very easy; just: ``df['Close'].plot()``.\n",
    "\n",
    "You can see that we're creating more advanced visualizations by combining multiple columns or by creating statistical visualizations (box plots, histograms, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close'].plot(figsize=(14, 7), title='S&P Closing Price | 2017 - 2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more advanced chart combining ``Close Price`` and ``Volume``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = df['Close'].plot(figsize=(14, 7), title='S&P Closing Price | 2017 - 2022')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "df['Volume'].plot(ax=ax2, color='red', ylim=[df['Volume'].min(), df['Volume'].max() * 5])\n",
    "\n",
    "ax1.figure.legend([\"Close\", \"Volume\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few statistical visualizations.\n",
    "\n",
    "A histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Volume'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A box plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Volume'].plot(kind='box', vert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas excels at Data Wrangling/handling/munging. We can perform a ton of operations, like combining datasets, grouping, melting, creating pivot tables, etc. We have an entire Skill Track just dedicated to Data Wrangling, so you can guess how powerful it is.\n",
    "\n",
    "For now, we'll focus on just a few simple operations. We'll calculate [Bollinger Bands](https://en.wikipedia.org/wiki/Bollinger_Bands) for our S&P500 data.\n",
    "\n",
    "Bollinger bands are just a simple visualization/analysis technique that creates two bands, one \"roof\" and one \"floor\" of some \"support\" for a given time series. The reasoning is that, if the time series is \"below\" the \"floor\", it's a historic low, and if it's \"above\" the \"roof\", it's a historic high. In terms of stock prices and other financial instruments, when the price crosses a band, it's said to be too cheap or too expensive.\n",
    "\n",
    "> **This is definitively NOT investment advice. Bollinger bands have proved to be INACCURATE, so don't use them in real life. This is just for educational purposes.**\n",
    "\n",
    "A Bollinger band is defined as two standard deviations above/below the Simple Moving Average. Those are a lot of concepts, but basically we can first define the Simple Moving Average, using the ``.rolling(WINDOW).mean()`` method (switch to the lab to follow along).\n",
    "\n",
    "Understanding the SMA is outside of the scope of this project, but it's basically a \"smoothing\" method. You see how the SMA *follows* the Close Price, but without so much volatility.\n",
    "\n",
    "Now, to define the bands we need to calculate 2 standard deviations above/below the price:\n",
    "\n",
    "```python\n",
    "df['Lower Band'] = df['Close SMA'] - (2 * df['Close'].rolling(60).std())\n",
    "df['Upper Band'] = df['Close SMA'] + (2 * df['Close'].rolling(60).std())\n",
    "```\n",
    "\n",
    "The final result should look something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close SMA'] = df['Close'].rolling(60).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos el nuevo SMA con el valor de cierre de la acción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Close', 'Close SMA']].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[['Close', 'Close SMA']].plot(figsize=(14,7), title='Close Price & its SMA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcularemos las bandas de Bollinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Lower Band'] = df['Close SMA'] - (2 * df['Close'].rolling(60).std())\n",
    "df['Upper Band'] = df['Close SMA'] + (2 * df['Close'].rolling(60).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Close', 'Close SMA', 'Lower Band', 'Upper Band']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Close', 'Lower Band', 'Upper Band']].plot(figsize=(14,7), title='Close Price & its SMA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora encontraremos los puntos bajos que cruzan la banda baja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[['Close', 'Lower Band', 'Upper Band']].plot(figsize=(14, 7), title='Close Price & its SMA')\n",
    "ax.annotate(\n",
    "    \"Let's find this point\", xy=(pd.Timestamp(\"2020-03-23\"), 2237), \n",
    "    xytext=(0.9, 0.1), textcoords='axes fraction',\n",
    "    arrowprops=dict(facecolor='red', shrink=0.05),\n",
    "    horizontalalignment='right', verticalalignment='bottom');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer un query de todas las fechas que cruzaron la banda baja en el periodo ``2020-03-01`` a ``2020-06-01`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['2020-03-01': '2020-06-01'].query(\"Close < `Lower Band`\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y podemos hacer un zoom también a ese periodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['2020-01-01': '2020-06-01', ['Close', 'Lower Band', 'Upper Band']].plot(figsize=(14, 7), title='Close Price & its SMA | 2020-01-01 to 2020-06-01');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series Practice with World Bank's data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will use pandas to explore the World Bank's data on economic, political, and social indicators for countries around the world. The data is collected from Kaggle.\n",
    "\n",
    "The World Bank data is organized into a number of different categories, including:\n",
    "\n",
    "- Economy: This category includes data on GDP, population, inflation, and unemployment.\n",
    "- Government: This category includes data on government spending, taxes, and debt.\n",
    "- Social: This category includes data on education, health, and poverty.\n",
    "\n",
    "The data is stored in excel file named ``world_data.xls``. In this lab, you will learn how to:\n",
    "\n",
    "- Create pandas series\n",
    "- Series basic attributes, such as shape, size, and data type\n",
    "- Access data in pandas series\n",
    "- Perform basic statistical operations on pandas series\n",
    "\n",
    "By the end of this lab, you will be able to use pandas to explore and analyze the World Bank's data on economic, political, and social indicators for countries around the world.\n",
    "\n",
    "> ***Run all the cells that are under Take a look at raw data heading in the notebook.***\n",
    "\n",
    "Let's get dive into the lab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('world_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a pandas series from a dataframe df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting columns to pandas series\n",
    "country_name = pd.Series(df['Country Name'])\n",
    "country_code = pd.Series(df['Country Code'])\n",
    "population = pd.Series(df[' Population, total '])\n",
    "gdp = pd.Series(df['GDP, PPP (current international $)'])\n",
    "internet_users = pd.Series(df['Internet users (per 100 people)'])\n",
    "life_expectancy = pd.Series(df['2014 Life expectancy at birth, total (years)'])\n",
    "literacy_rate = pd.Series(df['Literacy rate, adult female (% of females ages 15 and above)'])\n",
    "exports = pd.Series(df['Exports of goods and services (% of GDP)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internet_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_expectancy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy_rate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the data type of the ``country_name`` series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ser ``dtype('O')` sabemos que el tipo de datos es **Objeto** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is the ``size`` of the gdp series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What is the data type of the ``internet_users`` series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internet_users.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What is the value of the first element in the ``population`` series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What is the value of the last element in the ``life_expectancy`` series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_expectancy.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What is the value of the element with index 29 in the ``literacy_rate`` series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy_rate.iloc[29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. What is the value of the last element in the ``gdp`` series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. What is the mean of the ``internet_users`` series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internet_users.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. What is the standard deviation of the ``internet_users`` series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internet_users.std( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 What is the median of the ``exports`` series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exports.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. What is the minimum value in the ``life_expectancy`` series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_expectancy.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. What is the ``average`` literacy rate of all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy_rate.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Sort the series in ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name_sorted = country_name.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Sort multiple series at once\n",
    "\n",
    "    Both the series ``country_name`` and ``literacy_rate`` have the same number of elements and the elements are in the same order with respect to index number. Arrange the country name as per ascending order of literacy rate. Assign the result of country name to new variable called ``country_name_sorted_by_literacy_rate`` and the result of literacy rate to new variable called ``literacy_rate_sorted``.\n",
    "\n",
    "    Example: If the country name is ``['India', 'China', 'Japan']`` and literacy rate is ``[80, 90, 70]``, then the result should be ``['Japan', 'India', 'China']`` and ``[70, 80, 90]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "literacy_rate_sorted = literacy_rate.sort_values(ascending=True)\n",
    "country_name_sorted_by_literacy_rate = country_name.loc[literacy_rate_sorted.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Pandas Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a lot to unpack. Let's better use an example. Take a look at the following \"table\" that contains a list of Top Companies (in technology) and their revenue (in millions of dollars):\n",
    "\n",
    "\n",
    "Preview\n",
    "A pandas Series will help us represent that data. Now it's time to turn on the lab and head to the Notebook, where we'll see how Series work.\n",
    "\n",
    "The syntax to create a series is:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "pd.Series(data, index, name=\"A name\")\n",
    "```\n",
    "\n",
    "``Series``s main components are:\n",
    "\n",
    "- **data**: this is the data that we want to represent, and obviously, we could say the \"most important\" component of the series. In our example, the data is the revenue of the companies.\n",
    "\n",
    "- **index**: the index indicates the \"labels\" of the data we're storing. We'll use the index to \"reference\" the data later. Indices are not required; pandas will assign a default sequential index if we don't provide one.\n",
    "\n",
    "- **name**: a series can contain a \"name\"; this will make more sense when we start using DataFrames. For now, just think about it as extra \"documentation\"; more clarity when working with your code. *Names are optional*.\n",
    "\n",
    "Finally, it's important to note that Series are \"strongly typed\": this means they have an associated (**an enforced object type**). It's not like in Python dictionaries, where we can mix types. In this case, you'll see that the series is of type int64 (it says dtype: int64 after the name, at the bottom of the representation). Don't worry too much about it for now, it's basically a Series containing \"integers\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll represent them using a Series in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [\n",
    "    'Apple', 'Samsung', 'Alphabet', 'Foxconn',\n",
    "    'Microsoft', 'Huawei', 'Dell Technologies',\n",
    "    'Meta', 'Sony', 'Hitachi', 'Intel',\n",
    "    'IBM', 'Tencent', 'Panasonic'\n",
    "]\n",
    "\n",
    "s = pd.Series([\n",
    "    274515, 200734, 182527, 181945, 143015,\n",
    "    129184, 92224, 85965, 84893, 82345,\n",
    "    77867, 73620, 69864, 63191],\n",
    "    index=companies,\n",
    "    name=\"Top Technology Companies by Revenue\")\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Check your knowledge: create a series**\n",
    "\n",
    "    Create a series under the variable ``my_series`` that contains three elements ``9``, ``11`` and -``5``. The index of the series should be ``['a', 'b', 'c']`` and the name should be ``\"My First Series\"``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = [9,11,-5]\n",
    "index = ['a', 'b', 'c']\n",
    "name = 'My First Series'\n",
    "my_series = pd.Series(elements, index=index, name= name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic selection and location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series are very flexible about querying/selecting data. You can get data by the index (get the revenue of Apple), by position (get the 5th element) and also by multiple of those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting by index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Series' index to reference and locate the data associated with a given label.\n",
    "\n",
    "For example, to get the revenue of *Apple*, we can do: ``s[\"Apple\"]``. That works, as you can see in the notebook. But you'll also see that we use a ``.loc`` attribute, making it: ``s.loc[\"Apple\"]``. This is the preferred method to reference values. It might make little sense for now, but it will once we start dealing with DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['Apple']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``.loc`` is the preferred way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc['Apple']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting by position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select elements by their \"order\". After all, as we mentioned in the previous section, **Series are ordered data structures**. So we can select an element by its position: for example, the 'first\", \"last\", \"third\", or \"253rd\" element. To select an element by its position, we use the ``.iloc`` attribute. The beauty of ``.iloc`` is that, as selection in Python lists, it accepts negative numbers to reference elements from the end of the series. That means that ``.iloc[-1]`` returns the **LAST** element in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors in selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As expected, if you try to retrieve an element that doesn't exist, it'll cause an error. This works pretty similarly as in Python dictionaries and lists. Selecting by index (.loc) fails with a ``KeyError`` (like dictionaries) and selecting by position fails with an ``IndexError`` as with lists.\n",
    "\n",
    "Most of the time, you can prevent these errors using the membership operator ``in``, which checks if a given element is part of the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code will fail\n",
    "s.loc[\"Non existent company\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code also fails, 132 it's out of boundaries\n",
    "# (there are not so many elements in the Series)\n",
    "s.iloc[132]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could prevent these errors using the membership check ``in``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Apple' in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Snapchat' in s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, Series look like glorified dictionaries. But this single feature will set them apart.\n",
    "\n",
    "> **With both, index selection and positional selection, you can pass multiple elements to be returned. This is extremely convenient.**\n",
    "\n",
    "Pay attention to the value returned: another Series, a \"sub-series,\" we could say, only with the values requested. In Pandas you'll see this pattern everywhere: Series selection returns other series, DataFrames selection (in future lessons) returns other DataFrames or other Series, etc.\n",
    "\n",
    "Let's see it in action. To select several elements (by index/label), we just pass a list of the labels:\n",
    "\n",
    "```py\n",
    "s.loc[[\"Apple\", \"Intel\", \"Sony\"]]\n",
    "```\n",
    "\n",
    "To select multiple values by position, we also pass a list with the positions:\n",
    "\n",
    "```py\n",
    "s.iloc[[0, 5, -1]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[['Apple', 'Intel', 'Sony']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[[0, 5, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Check your knowledge: location by index**\n",
    "\n",
    "    Select the revenue of ``Intel`` and store it in a variable named ``intel_revenue``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intel_revenue = s.loc['Intel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Check your knowledge: location by position**\n",
    "\n",
    "    Select the revenue of the \"second to last\" element in our series ``s`` and store it in a variable named ``second_to_last``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_to_last = s.iloc[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Check your knowledge: multiple selection**\n",
    "\n",
    "    Use multiple label selection to retrieve the revenues of the companies:\n",
    "\n",
    "    - Samsung\n",
    "    - Dell Technologies\n",
    "    - Panasonic\n",
    "    - Microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_series = s.loc[[\"Samsung\", 'Dell Technologies', \"Panasonic\", 'Microsoft']]\n",
    "sub_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series Attributes and Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series contain a lot of useful attributes and methods to interact with them. Probably the two most common ones you'll see all the time are ``.head()`` and ``.tail()``. This just returns 5 elements either from the beginning of the series (``.head()``) or from the end of it (``.tail()``). This is useful when you're working with real data (possibly MILLIONS of values). You can also pass a number of elements to return: ``.head(3)`` and ``.tail(2)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a series is constructed (somehow), we can access all the attributes separately. Namely:\n",
    "\n",
    "- The data of the series: using the ``.values`` attribute\n",
    "- The index: using ``.index``\n",
    "- The name: using ``.name``\n",
    "- The type assigned: using ``.dtype``\n",
    "- The number of elements: using ``.size``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``len`` also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that's not all about attributes and Series. As you might already know, we use Pandas for data processing. And a significant component of data processing is understanding its statistical implications.\n",
    "\n",
    "The ``.describe()`` method gives you quick summary statistics of your series.\n",
    "\n",
    "There are also individual methods for each of the values returned by ``.describe()``: ``.max()``, ``.min()``, ``.mean()``, ``.median()``, etc.\n",
    "\n",
    "There's also a ``quantile()`` method to check for specific quantiles (or percentiles). For example, to get the 75th percentile, you can use: ``s.quantile(.75)``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to complete the activity\n",
    "american_companies = s[[\n",
    "    'Meta', 'IBM', 'Microsoft',\n",
    "    'Dell Technologies', 'Apple', 'Intel', 'Alphabet'\n",
    "]]\n",
    "american_companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have selected a \"sub-series\" of only american companies in the variable ``american_companies``. Using that Series, complete the following activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **What's the average revenue of American Companies?**\n",
    "\n",
    "    What's the average revenue of the companies contained in the variable ``american_companies``? Enter the whole number (that is, without decimals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_companies.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **What's the median revenue of American Companies?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_companies.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting series is extremely simple. This is another great feature of pandas in general.\n",
    "\n",
    "But with Sorting, we'll introduce two important concepts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting by values or Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, what are we sorting by? The values? Or the index? Well, we'll be able to sort by both attributes: using the ``.sort_values()`` and ``.sort_index()`` methods.\n",
    "\n",
    "Check the examples in the notebook. To sort the values of the series (that is, the revenue), we use the ``.sort_values()`` method. To sort the series by its index (in this case, lexicographically by the company's name, we use the ``.sort_index()`` method). The default sorting method is in \"ascending\" order. To sort in descending order, you must pass the ``ascending=False`` parameter (to either method)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **What company has the largest revenue?**\n",
    "\n",
    "    Using all the companies (stored in the Series in ``s``), which company has the largest revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sort_values(ascending=False)[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **Sort company names lexicographically. Which one comes first?**\n",
    "\n",
    "    Using all the companies (stored in the Series in ``s``), which name is the \"first\" one in lexicographic (*or alphabetical*) order. That is, ``aa`` comes before than ``ab``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sort_index(ascending=True)[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inmutability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second important concept is **immutability**, and this is NOT just a Series concept; it's a widespread concept in pandas and Data Science in general. In this case, you'll see that when we \"sort a series\", **we don't ACTUALLY sort the series itself**. There's a NEW series returned. The underlying series has NOT changed; it has NOT been mutated.\n",
    "\n",
    "This is a CRUCIAL concept in Data Science in general. We don't want to change/mutate things, as it's harder to keep track of these changes.\n",
    "\n",
    "If by any chance, you DO want to mutate your series, in this case, you want to sort it and alter the underlying series (in ``s`` in this case), you must pass the ``inplace=True`` attribute. When doing so, you'll see that this time the method doesn't return anything, but the underlying series (in s has changed) to contain the data in the order required.\n",
    "\n",
    "Again, immutability is both preferred and encouraged, so try to use immutable methods as much as possible. For example, it is fine to create a second variable with the values sorted (``s_sorted_values``) and without changing ``s``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will sort the series by revenue, ascending, and we'll mutate the original one. Notice how the method doesn't return anything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sort_values(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now the series is sorted by revenue in ascending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now sort the series by index, mutating it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **Sort American Companies by Revenue**\n",
    "\n",
    "    Create a new variable ``american_companies_desc`` that contains the results of sorting ``american_companies`` by revenue (this is, by value) in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to complete the activity\n",
    "american_companies = s[[\n",
    "    'Meta', 'IBM', 'Microsoft',\n",
    "    'Dell Technologies', 'Apple', 'Intel', 'Alphabet'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_companies_desc = american_companies.sort_values(ascending=False)\n",
    "american_companies_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. **Sort (and mutate) international companies**\n",
    "    \n",
    "    Now it's time to do what we told you NOT to do, but we need practice it. There's a new series defined named international_companies. Your task is to sort them by Revenue in **descending order** (larger to smaller) but doing it in place, that is, modifying the series.\n",
    "\n",
    "    If you make a mistake, you can always re-run the cell that generates the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to complete the activity\n",
    "international_companies = s[[\n",
    "    \"Sony\", \"Tencent\", \"Panasonic\",\n",
    "    \"Samsung\", \"Hitachi\", \"Foxconn\", \"Huawei\"\n",
    "]]\n",
    "international_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "international_companies.sort_values(ascending=False, inplace=True)\n",
    "international_companies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying series is something we hardly want to do. As mentioned in the previous section, we try to be \"immutable\". So changing series is usually not recommended.\n",
    "\n",
    "But still, it's possible to modify series by changing values, adding or removing elements. This works in the same way as with Python dictionaries.\n",
    "\n",
    "For example, to modify an existing value, we can just \"step over it\", let's say we want to set IBM's revenue to $0. We can just do:\n",
    "\n",
    "```py\n",
    "s['IBM'] = 0\n",
    "```\n",
    "To add elements (or change the value of an element), you can just use the index of the new element: ``s['Tesla'] = 21450``.\n",
    "\n",
    "To remove an element, we use the del keyword and the index: ``del s[\"Apple\"]``.\n",
    "\n",
    "Again, these are the same ways we use to add/remove elements from dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['IBM']  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sort_values().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['Tesla'] = 21450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sort_values().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. **Insert Amazon's Revenue**\n",
    "\n",
    "    Insert a new element in our series ``s``, Amazon with a total revenue of: ``$469,822`` (million dollars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['Amazon'] = 469822"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. **Delete the revenue of Meta**\n",
    "\n",
    "    Remove the entry for Meta from the series ``s``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del s['Meta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating Series (immutable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if you want to \"concatenate\" two series, you can use the ``concat()`` method ``s.concat(dataframe1 or series1, dataframe2 or series2)`` as shown in the example in the notebook. In this case, the method returns a new series or dataframe with the values of the two series/dataframe concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_s = pd.Series([21_450, 4_120], index=['Tesla', 'Snapchat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_new = pd.concat([s, another_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series Practice with S&P Companies Market Cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to put all you've learned about series to a test. Let's start by introducing the data we'll be working with. Make sure you've started your lab, and the Notebook is on the right panel.\n",
    "\n",
    "For this project, we'll be working with the \"market capitalization\" of S&P500 (short for \"Standard and Poor's 500\") companies. The S&P 500 is a free-float, capitalization-weighted index of the top 500 publicly listed stocks in the US (top 500 by market cap). To put it simply: a list of the \"most valuable companies in US Markets\".\n",
    "\n",
    "> **Disclaimer: the data is outdated. As you might know, markets change very rapidly.**\n",
    "\n",
    "But this project has a twist. We will be using two series instead of one that we'll read from two different datasets. The first one is the stock symbols of companies. For example, Apple, Inc. stock symbol is ``AAPL`` (usually styled $AAPL). Facebook's symbol is ``FB`` ($FB).\n",
    "\n",
    "The second dataset contains the market cap of each company by its symbol. For example, the market cap of ``AAPL`` (Apple Inc.) is ``$809,508,034,020``.\n",
    "\n",
    "The first thing you'll see in the Notebook is a preview of the underlying datasets we're using: ``sp500-symbols.csv`` and ``sp500-marketcap.csv``. Next, we use the ``head`` Linux command to peek at each file's first five lines.\n",
    "\n",
    "We then import pandas (``import pandas as pd``) and load the data into series using the ``read_csv`` method. Don't worry about it yet! We'll use A LOT of ``read_csv`` during this track, so you'll get pretty used to it soon.\n",
    "\n",
    "At the end of those operations, you'll have two series containing the data we'll be working with. One is ``market_cap`` (that includes market cap by symbol), and the other is ``symbols`` that contain the names of the companies and their stock symbol.\n",
    "\n",
    "Take a few minutes to familiarize yourself with both Series, and then let's get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap = pd.read_csv(\"sp500-marketcap.csv\", index_col=\"Symbol\")['Market Cap']\n",
    "market_cap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = pd.read_csv(\"sp500-symbols.csv\", index_col=\"Name\")['Symbol']\n",
    "symbols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Series Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by doing a simple *reconnaissance* of the series we're working with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Name of the market_cap Series**\n",
    "\n",
    "    What's the name of the series contained in the ``market_cap`` variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Name of the symbols Series**\n",
    "\n",
    "    What's the name of the series contained in the ``symbols`` variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **What's the dtype of ``market_cap``**\n",
    "    \n",
    "    What's the dtype of the series contained in the ``market_cap`` variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **What's the dtype of ``symbols``**\n",
    "\n",
    "    What's the dtype of the series contained in the symbols variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **How many elements do the series have?**\n",
    "\n",
    "    How many elements ``market_cap`` series contains?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(market_cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **What's the minimum value for Market Cap?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **What's the maximum value for Market Cap?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "8. **What's the average Market Cap?**\n",
    "\n",
    "    Find the average value for Market Cap, and enter it WITHOUT decimals. Just the integer number (if you find the average is 1948.88, just enter 1948)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **What's the median Market Cap?**\n",
    "\n",
    "    Find the median value for Market Cap, and enter it WITHOUT decimals. Just the integer number (if you find the median is 1948.0, just enter 1948)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection and Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to do practice some selection and indexing using Series. We'll start with some basic activities with each series, and by the end we'll be using both of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. **What's the symbol of ``Oracle Corp``.?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols.loc['Oracle Corp.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. **What's the Market Cap of ``Oracle Corp.``?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap.loc['ORCL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. **What's the Market Cap of ``Wal-Mart Stores``?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap.loc[symbols.loc['Wal-Mart Stores']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. **What's the symbol of the 129th company?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols.iloc[128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. **What's the Market Cap of the 88th company in ``symbols``?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning! The companies might be out of order... so the 88th company in ``symbols`` might not be the same as the 88th one in ``market_cap``. We need you to find the 88th company in ``symbols`` first, and then the the Market Cap from ``market_cap`` for that particular symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap.loc[symbols.iloc[87]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. **Create a new series only with FAANG Stocks**\n",
    "\n",
    "    There's a common term in investing (and in tech) which is FAANG companies. This refers to \"big tech\" companies by their acronyms. For example, ``FAANG`` means the following companies: Facebook Apple Amazon Netflix and Google (read more about FAANG and Big Tech in Wikipedia).\n",
    "\n",
    "    > Here FAANG refers to acronym of few companies but there are other big tech companies like Microsoft. So, the term FAANG is not a strict definition of big tech companies.\n",
    "\n",
    "    Your task is to create a new series, under the variable ``faang_market_cap``, containing the market cap of the following companies:\n",
    "\n",
    "    - ``Amazon.com Inc``\n",
    "    - ``Apple Inc.``\n",
    "    - ``Microsoft Corp.``\n",
    "    - ``Alphabet Inc Class A`` (this is Google's main stock)\n",
    "    - ``Facebook, Inc.``\n",
    "    - ``Netflix Inc.``\n",
    "\n",
    "    **Important**! The stocks must be in THIS order. You will need to find the Symbols of the companies first.\n",
    "\n",
    "    Also important, as stated above, you MUST create a variable containing your new series. Your code should look something like:\n",
    "\n",
    "    ``faang_market_cap = ... # your code``\n",
    "    \n",
    "    There's a way to combine everything in a one-liner. Try to solve this task without looking at the solution; but after you've finished it, take a peak at it because there's a neat trick explained at the end of the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap.sort_values(ascending=False).head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_market_cap = pd.Series([market_cap.loc[symbols['Amazon.com Inc']],\n",
    "                              market_cap.loc[symbols['Apple Inc.']],\n",
    "                              market_cap.loc[symbols['Microsoft Corp.']],\n",
    "                              market_cap.loc[symbols['Alphabet Inc Class A']],\n",
    "                              market_cap.loc[symbols['Facebook, Inc.']],\n",
    "                              market_cap.loc[symbols['Netflix Inc.']]\n",
    "                              ], index= [symbols['Amazon.com Inc'],\n",
    "                                         symbols['Apple Inc.'],\n",
    "                                         symbols['Microsoft Corp.'],\n",
    "                                         symbols['Alphabet Inc Class A'],\n",
    "                                         symbols['Facebook, Inc.'],\n",
    "                                         symbols['Netflix Inc.']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_market_cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One neat trick with Pandas is that we can use the values of one series to select elements from another series. So we could have just done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_market_cap2 = market_cap[symbols[[\"Amazon.com Inc\", \"Apple Inc.\", \"Microsoft Corp.\", \"Alphabet Inc Class A\", \"Facebook, Inc.\", \"Netflix Inc.\", ]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_market_cap2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. **Select the market cap of companies in position 1st, 100th, 200th, etc.**\n",
    "\n",
    "    The S&P500 index contains 500 companies. Create a variable ``position_companies`` that contains the market cap of the companies in the positions:\n",
    "\n",
    "    - 1st\n",
    "    - 100th\n",
    "    - 200th\n",
    "    - 300th\n",
    "    - 400th\n",
    "    - 500th\n",
    "    \n",
    "    **Important!** This selection should be done under ``market_cap``. Don't use ``symbols`` for this particular activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_companies = market_cap.iloc[[0,99,199,299,399,499]]\n",
    "position_companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. **What's the 4th company sorted lexicographically by their symbol?**\n",
    "\n",
    "    Use the ``symbols`` series to sort **the symbols** in lexicographical order (ascending). Which company (the name, the index value) appears in the 4th position? Note: the answer is the full company name. For example, the full name of ``MSFT`` (Microsoft) is ``Microsoft Corp.``, as it appears in the index. The correct answer would be Microsoft Corp.. By the way, Microsoft is definitively NOT the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols.sort_values(ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. **What's the Market Cap of the 7th company (in descending order)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ``market_cap`` series, sort the companies by their symbol in lexicographical order in **descending mode** and enter the revenue of the 7th company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap.sort_index(ascending=False)[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Series Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will practice filtering with conditionals and sorting on pandas series using dataset that contains information about international cricket players who have played since 2002. The data includes the player's name, number of innings they have played, number of runs they have scored, number of balls they have faced, number of times they have been dismissed, their batting average, their strike rate, their highest score, number of fours they have hit, number of sixes they have hit, number of times they have scored a half-century, and number of times they have scored a century.\n",
    "\n",
    "Below are the columns of the dataset:\n",
    "\n",
    "- Player: Name of the player\n",
    "- I: Number of innings played\n",
    "- R: Number of runs scored\n",
    "- B: Number of balls faced\n",
    "- Outs: Number of times dismissed\n",
    "- Avg: Batting average\n",
    "- SR: Strike rate\n",
    "- HS: Highest score\n",
    "- 4s: Number of fours hit\n",
    "- 6s: Number of sixes hit\n",
    "- 50: Number of times scored a half-century\n",
    "- 100: Number of times scored a century\n",
    "\n",
    "Let's get started with the lab now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"leadersdata.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('Player', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pandas series for each column\n",
    "innings = data['I']\n",
    "runs = data['R']\n",
    "balls = data['B']\n",
    "outs = data['Outs']\n",
    "batting_average = data['Avg']\n",
    "strike_rate = data['SR']\n",
    "highest_score = data['HS']\n",
    "number_of_fours = data['4s']\n",
    "number_of_sixes = data['6s']\n",
    "number_of_fifties = data['50']\n",
    "number_of_hundreds = data['100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the first 5 rows of each series\n",
    "print(\"Innings:\\n\", innings.head())\n",
    "print(\"Runs:\\n\", runs.head())\n",
    "print(\"Balls:\\n\", balls.head())\n",
    "print(\"Outs:\\n\", outs.head())\n",
    "print(\"Batting Average:\\n\", batting_average.head())\n",
    "print(\"Strike Rate:\\n\", strike_rate.head())\n",
    "print(\"Highest Score:\\n\", highest_score.head())\n",
    "print(\"Number of Fours:\\n\", number_of_fours.head())\n",
    "print(\"Number of Sixes:\\n\", number_of_sixes.head())\n",
    "print(\"Number of Fifties:\\n\", number_of_fifties.head())\n",
    "print(\"Number of Hundreds:\\n\", number_of_hundreds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **How many players have a batting average greater than 30 in the ``batting_average`` series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_average.loc[lambda x : x > 30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batting_average[batting_average > 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **What is the maximum number of runs scored by a player in the ``runs`` series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Name the player with maximum runs**\n",
    "\n",
    "    Write the name of the player who has scored the maximum number of runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.sort_values(ascending=False)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs[runs == runs.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Name the player who played least number of balls**\n",
    "\n",
    "    There is a possibility that more than one player has played the least number of balls. In that case, write the names of first and last players names separated by a comma. For example, write ``A, B``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balls[balls == balls.min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **How many players have played more than 500 balls in the ``balls`` series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(balls[balls > 500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **What is the mean value of the batting_average series**\n",
    "\n",
    "    Write your answer in the form of a number with 2 decimal places. For example, if the answer is 1.234567, write 1.23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_average.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **How many players have a strike rate not equal to 70 in the ``strike_rate`` series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(strike_rate[strike_rate != 70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **What is the minimum number of innings played by a player in the ``innings`` series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innings.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **How many players have a batting average greater than 50 in the ``batting_average`` series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batting_average[batting_average > 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. **How many players have a batting average between 20 and 30 (inclusive) in the ``batting_average`` series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batting_average.loc[lambda x : (x >= 20) & (x <= 30)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. **Calculating the Average Balls Faced by a Player**\n",
    "\n",
    "    The ``balls`` series contains information about the number of balls faced by different players in a cricket match. The task is to calculate the average number of balls faced by a player.\n",
    "\n",
    "    Round off the result to two decimal places. For example, if the answer is 123.456789, write 123.46."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balls.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. **How many players have a strike rate greater than 120 in the ``strike_rate`` series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(strike_rate[strike_rate > 120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. **Provide the names of the top three players from the ``strike_rate`` series**\n",
    "\n",
    "    Write the names of the players in the decreasing order of their strike rate separated by a comma. For example, write ``A, B, C``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strike_rate.sort_values(ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. **Sum of Maximums from ``number_of_fours`` and ``number_of_sixes`` Series**\n",
    "\n",
    "    The goal is to calculate the sum of the maximum values from both series combined. For example, if the maximum value in ``number_of_fours`` is ``10`` and the maximum value in ``number_of_sixes`` is ``20``, then the answer is ``30``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_fours.max() + number_of_sixes.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. **How many players have a batting average below ``10`` in the ``batting_average`` series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batting_average[batting_average < 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. **Name the player who hit maximum sixes**\n",
    "\n",
    "    Write the player name along with the number of sixes hit by the player separated by a comma. For example, write ``A, 10``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_sixes[number_of_sixes == number_of_sixes.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. **How many players have a strike rate between 80 and 90 (inclusive) in the ``strike_rate`` series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(strike_rate[(strike_rate >= 80) & (strike_rate <= 90)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. **What is the total number of runs scored by all players in the ``runs`` series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. **What is the range (difference between the maximum and minimum values) of the ``number_of_fifties`` series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_fifties.max() - number_of_fifties.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. **How many players have a strike rate below 60 in the ``strike_rate`` series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(strike_rate[strike_rate < 60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. **Calculating the Mean Number of Boundaries (Fours + Sixes) Hit by a Player**\n",
    "\n",
    "    In this activity, you will be calculating the mean number of boundaries hit by a player. Boundaries include both fours and sixes. You will be given two series: ``number_of_fours`` and ``number_of_sixes``. Your task is to find the mean number of boundaries hit by combining the values from both series.\n",
    "\n",
    "    > Remember to round your answer to two decimal places. For example, if the mean number of boundaries is 1.453, write 1.45."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(number_of_fours + number_of_sixes).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. Players with highest score in ``highest_score`` series\n",
    "\n",
    "    Create a new series named ``top_five_scores`` that contains the top five players names with the highest score in the ``highest_score`` series. The series should be sorted in descending order based on the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_five_scores = highest_score.sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_five_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and Conditional Selection with Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to practice conditional selection with Series. We're going to use the same data as before with Companies' revenues.\n",
    "\n",
    "Conditional Selection is like \"filtering\" or \"querying\" (if you're familiar with SQL). It'll allow us to answer the following types of questions:\n",
    "\n",
    "- what companies made more than ``$X``?\n",
    "- what companies made less than ``$X``?\n",
    "- what companies made between ``$X`` and ``$Y``?\n",
    "\n",
    "Turn on your lab, and let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start introducing the concept of Boolean Arrays (which in turn, is a concept from NumPy, but you're not required to know NumPy to complete this).\n",
    "\n",
    "This concept might sound a little bit strange at the beginning, but trust us, it'll all make sense in the next section.\n",
    "\n",
    "Boolean Arrays is a way of selecting in which we pass the **full index** of the series, and we indicate what elements we want to select and which ones we want to skip. We indicate this by passing *Boolean* values: ``True`` and ``False``.\n",
    "\n",
    "Let's see an example to make it more clear. We're going to use Boolean Arrays to select only American companies. That is: Apple, Alphabet, Microsoft, Dell, Meta, Intel and IBM.\n",
    "\n",
    "Using Boolean Arrays, we need to pass the value ``True`` for each one of those companies, and ``False`` to all the remaining ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the example in the notebook to see it in action, but the syntax is basically:\n",
    "\n",
    "```py\n",
    "s.loc[[\n",
    "    True,      # Apple\n",
    "    False,     # Samsung\n",
    "    True,      # Alphabet\n",
    "    False,     # Foxconn\n",
    "    True,      # Microsoft\n",
    "    False,     # Huawei\n",
    "    True,      # Dell\n",
    "    True,      # Meta\n",
    "    False,     # Sony\n",
    "    False,     # Hitachi\n",
    "    True,      # Intel\n",
    "    True,      # IBM\n",
    "    False,     # Tencent\n",
    "    False,     # Panasonic\n",
    "]]\n",
    "```\n",
    "\n",
    "Please note that the list (or array) of boolean values passed must be of EQUAL length as the series index. We must pass a value, either ``True`` or ``False`` for ALL the values in the index. If we are not interested in selecting an element, we just pass ``False``.\n",
    "\n",
    "Now, this might feel like an \"inefficient\" way of selecting data. What happens if you have 1 million records? Are you supposed to type ``True`` or ``False`` for each one of those records? Of course not! In the next section it'll become more clear why Boolean Arrays are important.\n",
    "\n",
    "But first, it's your turn to practice Boolean Arrays and selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [\n",
    "    'Apple', 'Samsung', 'Alphabet', 'Foxconn',\n",
    "    'Microsoft', 'Huawei', 'Dell Technologies',\n",
    "    'Meta', 'Sony', 'Hitachi', 'Intel',\n",
    "    'IBM', 'Tencent', 'Panasonic'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([\n",
    "    274515, 200734, 182527, 181945, 143015,\n",
    "    129184, 92224, 85965, 84893, 82345,\n",
    "    77867, 73620, 69864, 63191],\n",
    "    index=companies,\n",
    "    name=\"Top Technology Companies by Revenue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[[\n",
    "    True,      # Apple\n",
    "    False,     # Samsung\n",
    "    True,      # Alphabet\n",
    "    False,     # Foxconn\n",
    "    True,      # Microsoft\n",
    "    False,     # Huawei\n",
    "    True,      # Dell\n",
    "    True,      # Meta\n",
    "    False,     # Sony\n",
    "    False,     # Hitachi\n",
    "    True,      # Intel\n",
    "    True,      # IBM\n",
    "    False,     # Tencent\n",
    "    False,     # Panasonic\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select only the Japanese companies\n",
    "\n",
    "    Create a Boolean Array that will select only the Japanese companies in our Series:\n",
    "\n",
    "    - Sony\n",
    "    - Hitachi\n",
    "    - Panasonic\n",
    "    \n",
    "    Store the array in the variable ``japanese_boolean_array``.\n",
    "\n",
    "    Using that same array, select the companies from the Series and store them in a different variable named ``japanese_companies``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "japanese_boolean_array = [\n",
    "    False,      # Apple\n",
    "    False,     # Samsung\n",
    "    False,      # Alphabet\n",
    "    False,     # Foxconn\n",
    "    False,      # Microsoft\n",
    "    False,     # Huawei\n",
    "    False,      # Dell\n",
    "    False,      # Meta\n",
    "    True,     # Sony\n",
    "    True,     # Hitachi\n",
    "    False,      # Intel\n",
    "    False,      # IBM\n",
    "    False,     # Tencent\n",
    "    True,     # Panasonic\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "japanese_companies = s.loc[japanese_boolean_array]\n",
    "japanese_companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's when those Boolean Arrays will be really useful (and hopefully, finally click).\n",
    "\n",
    "Turns out that Series accept comparison operators (or boolean operators), like \"greater than\" (``>``), \"less than\" (``<``), etc. The interesting feature is that, the result of applying any of these operators to a Series, is a boolean array!.\n",
    "\n",
    "Let's see an example: in the notebook, you have an example of the expression ``s > 100_000``. This basically asks which values of the series are \"greater than\" 100,000 (which in turns means how many companies's revenue are greater than $100 billion).\n",
    "\n",
    "The result of that expression is the boolean *series*:\n",
    "\n",
    "```py\n",
    "Apple                 True\n",
    "Samsung               True\n",
    "Alphabet              True\n",
    "Foxconn               True\n",
    "Microsoft             True\n",
    "Huawei                True\n",
    "Dell Technologies    False\n",
    "Meta                 False\n",
    "Sony                 False\n",
    "Hitachi              False\n",
    "Intel                False\n",
    "IBM                  False\n",
    "Tencent              False\n",
    "Panasonic            False\n",
    "```\n",
    "\n",
    "We can combine this \"conditional\" expression, with the selection method seen before to put together a very powerful filtering and querying system.\n",
    "\n",
    "Example, let's ask:\n",
    "\n",
    "> **What are the companies which revenues exceed the $100 billion dollars?**\n",
    "\n",
    "We just need to combine the ``.loc`` expression with our boolean array:\n",
    "\n",
    "```py\n",
    "s.loc[s > 100_000]\n",
    "Apple        274515\n",
    "Samsung      200734\n",
    "Alphabet     182527\n",
    "Foxconn      181945\n",
    "Microsoft    143015\n",
    "Huawei       129184\n",
    "Name: Top Technology Companies by Revenue, dtype: int64\n",
    "```\n",
    "\n",
    "We can use any operator that we want: equals (``==``), different from (or not equals to ``!=``), greater than (``>``), greater than or equals to (``>=``), etc.\n",
    "\n",
    "Give it a try, complete the following activities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Select companies with less than $90,000M in Revenue**\n",
    "\n",
    "    Select those companies that have a revenue value less than ``90,000``, select them in a new variable named ``less_90_rev``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_90_rev = s.loc[s < 90000]\n",
    "less_90_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Select companies with revenue of more than $150,000M\n",
    "\n",
    "    Select those companies that have a revenue value greater than ``150,000``, select them in a new variable named ``more_150_rev``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_150_rev = s.loc[s > 150000]\n",
    "more_150_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Series methods with comparison operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should feel natural based on what we saw in the previous section, but it's still worth mentioning. You can combine comparison operators with Series methods to obtain more generic expressions. For example, let's select the company with the MOST revenue:\n",
    "\n",
    "``s.loc[s == s.max()]``\n",
    "\n",
    "Or we could find those companies with revenue above the average:\n",
    "\n",
    "``s.loc[s >= s.mean()]``\n",
    "\n",
    "Or, a more complex expression could be finding those companies who's revenue is greater than the average + one standard deviation (these concepts are covered in our Descriptive Statistics track; don't worry about the technical details now):\n",
    "\n",
    "``s.loc[s > (s.mean() + s.std())]``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company with the most revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[s == s.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Company with revenue above average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[s >= s.mean()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Companies who's revenue is greater than the average +1 standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[s > (s.mean() + s.std())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean operators are the and, or, not expressions used to \"concatenate\" conditions. They should be familiar from your Python background. In Pandas, we also have boolean operators that we can use to create more \"complex\" selection expressions, but they're not ``and``, ``or``, ``not`` as in Python, they are:\n",
    "\n",
    "- ``&`` for AND\n",
    "- ``|`` for OR\n",
    "- ``~`` for NOT\n",
    "\n",
    "Let's see them in action using the *OR* operator (``|``). We will compute the expression that selects the companies that have revenue greater than ``$150,000M`` **OR** less than ``$80,000``. Graphically, we want to select the following companies:\n",
    "\n",
    "Let's treat each expression separately; first, let's focus on those companies with revenue greater than $150,000:\n",
    "\n",
    "```py\n",
    ">>> s > 150_000\n",
    "```\n",
    "(see the result in the notebook)\n",
    "\n",
    "Then, those companies with revenue less than $80,000M:\n",
    "\n",
    "```py\n",
    ">>> s < 80_000\n",
    "```\n",
    "(see the result in the notebook)\n",
    "\n",
    "Now, let's put it altogether, using the | (OR) operator. IMPORTANT! When we combine comparison expressions using boolean operators, we must surround each expression in parentheses:\n",
    "\n",
    "```py\n",
    ">>> (s > 150_000) | (s < 80_000)\n",
    "Apple                 True\n",
    "Samsung               True\n",
    "Alphabet              True\n",
    "Foxconn               True\n",
    "Microsoft            False\n",
    "Huawei               False\n",
    "Dell Technologies    False\n",
    "Meta                 False\n",
    "Sony                 False\n",
    "Hitachi              False\n",
    "Intel                 True\n",
    "IBM                   True\n",
    "Tencent               True\n",
    "Panasonic             True\n",
    "```\n",
    "\n",
    "You can see the True values matching the same desired values as the image above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Companies with revenue greater than $150,000M or less than $80,000M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Revenue greater than $150,000M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s > 150_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Revenue less than $80,000M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s < 80_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(s > 150_000) | (s < 80_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting the companies matching the expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[(s  > 150_000)|(s < 80_000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The NOT (~) operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[s >= 150_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[~ (s >= 150_000 )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Select companies the companies with the MOST and LESS revenue**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[ (s == s.max()) | (s == s.min()) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Select companies with revenue between ``$80,000M`` and ``$150,000M``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[(s < 150_000) & (s > 80_000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicing Series Filtering with S&P500 and Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project you'll practice your Series filtering skills.\n",
    "\n",
    "Before we get started, let's introduce the datasets used. Make sure your lab is running!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both datasets used for this project were taken from the publicly available and Open Source RDatasets repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age of First Marriage\n",
    "\n",
    "The first one is titled **Age at first marriage of 5,534 US women** ([source](https://vincentarelbundock.github.io/Rdatasets/doc/openintro/age_at_mar.html)). It reads:\n",
    "\n",
    "> **Age at first marriage of 5,534 US women who responded to the National Survey of Family Growth (NSFG) conducted by the CDC in the 2006 and 2010 cycle.**\n",
    "\n",
    "There are a total of 5,534 observations.\n",
    "\n",
    "### S&P500 Returns (1990's)\n",
    "\n",
    "The second one is titled **Returns of the Standard and Poors 500** ([source](https://vincentarelbundock.github.io/Rdatasets/doc/MASS/SP500.html)) contains daily returns for S&P500 in the 1990's (1991-1999). It contains 2,780 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the pandas built-in ``read_csv`` method to read the data that is stored in CSV format. Most commonly, ``read_csv`` is used to read data into DataFrames, but as this project deals with ``Series``, we pass the parameter ``squeeze=True`` to make it a series. Bottom line is: don't worry about it for now, both datasets should be available for you in the variables ``age_marriage`` and ``sp500``.\n",
    "\n",
    "We can also display a quick histogram about our data to understand how it is distributed. This is completely optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# for visualizations, don't worry about these for now\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_marriage = pd.read_csv(\"age_at_mar.csv\", index_col=0).squeeze('columns')\n",
    "age_marriage.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_marriage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,7))\n",
    "sns.histplot(age_marriage, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S&P Returns 1990's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = pd.read_csv('SP500.csv', index_col=0).squeeze('columns')\n",
    "sp500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,7))\n",
    "sns.histplot(sp500, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Rename the series accordingly\n",
    "\n",
    "    Rename both series with the names specified below, given their variables:\n",
    "\n",
    "    - ``age_marriage``: should be named \"Age of First Marriage\"\n",
    "    - ``sp500``: should be named \"S&P500 Returns 90s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_marriage.name = \"Age of First Marriage\"\n",
    "sp500.name = \"S&P500 Returns 90s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What's the maximum Age of marriage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_marriage.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What's the median Age of Marriage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_marriage.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What's the minimum return from S&P500?\n",
    "\n",
    "    Enter the value with up 2 decimals of precision. Example, if the value is ``-11.8718``, enter only ``-11.87``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. How many Women marry at age 21?\n",
    "\n",
    "    21 is the most common age for marriage (you can check that using the .mode() method). How many women married at that age?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(age_marriage.loc[age_marriage == age_marriage.mode().iloc[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. How many Women marry at 39y/o or older?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(age_marriage.loc[age_marriage >= 39])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. How many positive S&P500 returns are there?\n",
    "\n",
    "    That is, a return greater than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sp500.loc[sp500 > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(sp500)\n",
    "ax.axvline(0, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. How many returns are less or equals than -2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sp500.loc[sp500 <= -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(sp500)\n",
    "ax.axvline(-2, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Selection with Boolean Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to combine conditionals using boolean operators to create more advanced filters. This time, we'll ask you to define new variables that will be checked dynamically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Select all women below 20 or above 39\n",
    "\n",
    "    Perform a selection of all the values in ``age_marriage`` that are below ``20`` or above ``39``. Store your results in the variable ``age_20_39``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig, ax = plt.subplots(figsize=(14, 7))\n",
    "sns.histplot(age_marriage, ax=ax)\n",
    "ax.add_patch(Rectangle((10, 0), 9, 450, alpha=.3, color='red'))\n",
    "ax.add_patch(Rectangle((39, 0), 5, 450, alpha=.3, color='red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_20_39 = age_marriage.loc[(age_marriage < 20) | (age_marriage > 39)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Select all women whose ages are even, and are older than 30 y/o\n",
    "\n",
    "    Perform a selection of all the values that are greater than ``30`` and even. Store your result in the variable ``age_30_even``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_30_even = age_marriage.loc[~(age_marriage % 2) & (age_marriage > 30)]\n",
    "age_30_even.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Select the S&P500 returns between 1.5 and 3\n",
    "    The ones depicted below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "sns.histplot(sp500, ax=ax)\n",
    "ax.add_patch(Rectangle((1, 0), 1.5, 250, alpha=.3, color='red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_15_to_3 = sp500.loc[(sp500 > 1.5) & (sp500 < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_15_to_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorized Operations with Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this brief project, we'll learn about \"Vectorized Operations\". In particular, we'll learn about Vectorized Operations applied to Pandas Series; but in reality, they're a concept original from NumPy, and we'll use it A LOT with DataFrames.\n",
    "\n",
    "So, the examples we'll see here might look trivial, but trust us that they'll be very useful throughout all your Pandas journey.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Vectorized Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorized Operations means just applying a \"global\" function to an entire Series. Let's derive an example from a Spreadsheet, in which we create a new column by applying an operation to ANOTHER column:\n",
    "\n",
    "With Series, it's going to be pretty much the same, it might look even simpler. Start the lab if you haven't already and take a look at the first operations.\n",
    "\n",
    "First, we initialize the Series we've been using, this time we name it ``revenue_in_millions``. That's the same series we've used so far, and it captures the revenue of the companies (listed in the Index) in Millions of dollars.\n",
    "\n",
    "We then create **A NEW** Series named ``revenue_in_billions`` just by dividing the whole Series by ``1000``:\n",
    "\n",
    "\n",
    "```py\n",
    ">>> revenue_in_billions = revenue_in_millions / 1000\n",
    "\n",
    "Apple                274.515\n",
    "Samsung              200.734\n",
    "Alphabet             182.527\n",
    "Foxconn              181.945\n",
    "Microsoft            143.015\n",
    "Huawei               129.184\n",
    "Dell Technologies     92.224\n",
    "Meta                  85.965\n",
    "Sony                  84.893\n",
    "Hitachi               82.345\n",
    "Intel                 77.867\n",
    "IBM                   73.620\n",
    "Tencent               69.864\n",
    "Panasonic             63.191\n",
    "```\n",
    "\n",
    "That's it! That's a vectorized operation. We say it's \"vectorized\" because it doesn't act on just 1 value, but in the whole *vector* of values contained in the Series.\n",
    "\n",
    "### Available Operators\n",
    "\n",
    "For now, we'll mostly focus on the regular arithmetic operators: ``+``, ``-``, ``*``, ``/``, ``**``, etc. But you'll see in further labs that we can create vectorized operations with String operations or even our own custom functions.\n",
    "\n",
    "### Practice time\n",
    "\n",
    "Now it's your turn to practice some vectorized operations before we advance to the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "companies = [\n",
    "    'Apple', 'Samsung', 'Alphabet', 'Foxconn',\n",
    "    'Microsoft', 'Huawei', 'Dell Technologies',\n",
    "    'Meta', 'Sony', 'Hitachi', 'Intel',\n",
    "    'IBM', 'Tencent', 'Panasonic'\n",
    "]\n",
    "\n",
    "revenue_in_millions = pd.Series([\n",
    "    274515, 200734, 182527, 181945, 143015,\n",
    "    129184, 92224, 85965, 84893, 82345,\n",
    "    77867, 73620, 69864, 63191],\n",
    "    index=companies,\n",
    "    name=\"Top Technology Companies by Revenue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding Vectorized Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_in_billions = revenue_in_millions / 1000\n",
    "revenue_in_billions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Subtract $50B from all companies in ``revenue_in_billions``\n",
    "\n",
    "    The recession just hit! Let's say you need to subtract *$50B* from all the companies in ``revenue_in_billions``. Store the new series in the variable ``revenue_recession``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_recession = revenue_in_billions - 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a new series expressing revenue in dollars (units)\n",
    "\n",
    "    The accounting team needs more detail when calculating EBITDA. They need revenue expressed in dollar units (instead of millions or billions). Use either series ``revenue_in_millions`` or revenue_in_billions to create a new series ``revenue_in_dollars``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_in_dollars = revenue_in_millions * 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations between Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we keep the analogy of spreadsheets, you'll see that it's also possible to create operations between different Series. For example, let's say recession hits again and the revenue of all companies is affected; but not equally. We want to reduce the revenue of each company by a given percentage. For example, Apple's new revenue will be 91% of the original one, Samsung's 93%, etc.\n",
    "\n",
    "Expressing that with Series, we first create the series ``recession_impact``, and apply the operation directly on the ``revenue_in_millions`` original series:\n",
    "\n",
    "```py\n",
    ">>> revenue_in_millions * recession_impact\n",
    "Apple                249808.65\n",
    "Samsung              186682.62\n",
    "Alphabet             178876.46\n",
    "Foxconn              176486.65\n",
    "Microsoft            141584.85\n",
    "Huawei               114973.76\n",
    "Dell Technologies     80234.88\n",
    "Meta                  70491.30\n",
    "Sony                  78950.49\n",
    "Hitachi               76580.85\n",
    "Intel                 69301.63\n",
    "IBM                   71411.40\n",
    "Tencent               67768.08\n",
    "Panasonic             59399.54\n",
    "```\n",
    "\n",
    "Now it's your turn to practice with Operations with Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recession_impact = pd.Series([\n",
    "    0.91, 0.93, 0.98, 0.97, 0.99, 0.89, 0.87,\n",
    "    0.82, 0.93, 0.93, 0.89, 0.97, 0.97, 0.94], index=companies)\n",
    "recession_impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of applying the recession impact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_in_millions * recession_impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the dollar amount of the impact by combining multiple operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute impact in Millions\n",
    "revenue_in_millions - (revenue_in_millions * recession_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute impact in Billions\n",
    "(revenue_in_millions - (revenue_in_millions * recession_impact)) / 1_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate revenue per employee, in dollars\n",
    "\n",
    "    Using the series ``number_of_employees`` (given in the notebook), your job is to calculate revenue ``per`` employee, expressed in dollars (units). Store it in the variable ``revenue_per_employee``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_employees = pd.Series([\n",
    "    164000, 266673, 150028, 1290000, 221000, 195000,\n",
    "    165000, 71970, 109700, 368250, 121100, 282100, 112771, 240198\n",
    "], index=companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_per_employee = revenue_in_dollars / number_of_employees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicing Series Vectorized Operations with Penguins Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to put your knowledge of vectorized operations on Pandas series to the test. In this lab, we will be working with a dataset that contains information about penguins. Each penguin is described by various attributes such as species, island, culmen length, culmen depth, flipper length, body mass, and gender.\n",
    "\n",
    "In this lab we will practice vectorized operations on Pandas series. We will learn how to perform arithmetic operations on series and apply mathematical functions to series.\n",
    "\n",
    "Throughout the lab, you will be presented with coding activities that require you to write code snippets to perform specific operations on the series. Each activity will be followed by a solution, allowing you to verify your code and understand the correct approach.\n",
    "\n",
    "In addition to individual topic-based activities, there will also be mixed-topic activities that require you to combine different operations to achieve a specific outcome. These activities will test your ability to apply multiple concepts simultaneously.\n",
    "\n",
    "By the end of this lab, you will have gained a solid understanding of vectorized operations on Pandas series and be able to manipulate and analyze data efficiently using these techniques.\n",
    "\n",
    "Let's dive into the activities and explore the power of vectorized operations on Pandas series!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv('penguins_cleaned.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns to pandas Series\n",
    "species = df['species']\n",
    "island = df['island']\n",
    "culmen_length_mm = df['culmen_length_mm']\n",
    "culmen_depth_mm = df['culmen_depth_mm']\n",
    "flipper_length_mm = df['flipper_length_mm']\n",
    "body_mass_g = df['body_mass_g']\n",
    "gender = df['sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Add a constant value of 100 to the ``body_mass_g`` series**\n",
    "\n",
    "    Create a new series called ``body_mass_g_plus_100`` by adding a constant value of 100 to the ``body_mass_g`` series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_mass_g_plus_100 = body_mass_g + 100\n",
    "body_mass_g_plus_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Subtract the ``culmen_length_mm`` series from the ``flipper_length_mm`` series**\n",
    "\n",
    "    Subtract the ``culmen_length_mm`` series from the ``flipper_length_mm`` series and assign the result to a new series called ``length_difference``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_difference = flipper_length_mm - culmen_length_mm\n",
    "length_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Multiply the ``culmen_depth_mm`` series by 2**\n",
    "\n",
    "    Multiply the ``culmen_depth_mm`` series by 2 and assign the result to a new series called ``double_culmen_depth_mm``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_culmen_depth_mm = culmen_depth_mm * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Raise the ``flipper_length_mm`` series to the power of 2**\n",
    "    \n",
    "    Create a new series called ``flipper_length_mm_squared`` by raising the ``flipper_length_mm`` series to the power of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipper_length_mm_squared = flipper_length_mm ** 2\n",
    "flipper_length_mm_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Calculate the mean of the ``culmen_length_mm`` series and subtract it from each value in the series**\n",
    "\n",
    "    Find the mean of the ``culmen_length_mm`` series and subtract it from each value in the series. Assign the result to a new series called ``culmen_length_mm_mean_centered``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "culmen_length_mm_mean_centered = culmen_length_mm - culmen_length_mm.mean()\n",
    "culmen_length_mm_mean_centered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Concatenate the ``species`` and ``gender`` series, separated by a hyphen ``-``**\n",
    "\n",
    "    Create a new series called ``species_and_gender`` by concatenating the ``species`` and ``gender`` series, separated by a hyphen (``-``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_and_gender = species.str.cat(gender, sep='-')\n",
    "species_and_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **Perform element-wise addition of ``culmen_length_mm`` and ``culmen_depth_mm``**\n",
    "\n",
    "    Add ``culmen_length_mm`` and ``culmen_depth_mm`` together and assign the result to a new variable called ``culmen_length_plus_depth_mm``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "culmen_length_plus_depth_mm = culmen_depth_mm + culmen_length_mm\n",
    "culmen_length_plus_depth_mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **Sort ``culmen_length_mm`` in descending order**\n",
    "\n",
    "    Create a new series called ``culmen_length_mm_sorted`` by sorting ``culmen_length_mm`` in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "culmen_length_mm_sorted = culmen_length_mm.sort_values(ascending=False)\n",
    "culmen_length_mm_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **Divide ``flipper_length_mm`` by ``culmen_length_mm``**\n",
    "\n",
    "    Find the ratio of each penguin's flipper length to its culmen length and assign the result to a new variable called ``length_ratio``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_ratio = flipper_length_mm / culmen_length_mm\n",
    "length_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series Practice: Vectorized operations using NBA data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to put to practice our Vectorized Operations with Series.\n",
    "\n",
    "The data we'll use is related to statistics of Players from the NBA since the year 1985. Although this practice is about Series, we'll start reading our data as a DataFrame. If you don't know what a DataFrame is yet, don't worry... this will actually be useful for the future. The only thing you need to know now is that each column of a DataFrame is a Series. And we're extracting several Series from the df:\n",
    "\n",
    "```py\n",
    "# Game info\n",
    "games_played = df['G']\n",
    "minutes_played = df['MP']\n",
    "\n",
    "# Field Goals info\n",
    "field_goals = df['FG']\n",
    "field_goals_attempts = df['FGA']\n",
    "\n",
    "# Free Throws info\n",
    "free_throws = df['FT']\n",
    "free_throws_attempts = df['FTA']\n",
    "```\n",
    "\n",
    "The index of the Series is the Player's name. So, for example, we can find the total field goals of Michael Jordan:\n",
    "\n",
    "```py\n",
    "field_goals.loc[field_goals.index == 'Michael Jordan*']\n",
    "```\n",
    "\n",
    "> ***The star (*) next to the player's name is because that player was selected for the \"Hall of Fame\" of the NBA.***\n",
    "\n",
    "Now, let's get started with our practice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nba_player_stats_1985.csv', index_col='Player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game info\n",
    "games_played = df['G']\n",
    "minutes_played = df['MP']\n",
    "\n",
    "# Field Goals info\n",
    "field_goals = df['FG']\n",
    "field_goals_attempts = df['FGA']\n",
    "\n",
    "# Free Throws info\n",
    "free_throws = df['FT']\n",
    "free_throws_attempts = df['FTA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_played.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_goals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_goals_attempts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Michael Jordan Field Goals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_goals.loc['Michael Jordan*']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Calculate field goal accuracy**\n",
    "\n",
    "    Calculate the \"Field Goal accuracy\" of a player by dividing their field goals by their total attempts then multiply by 100. Store the result in the variable ``field_goal_perc``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_goal_perc = field_goals / field_goals_attempts * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **What's the FG% of Michael Jordan**\n",
    "\n",
    "    Use the series created in the previous activity, field_goal_perc, to answer: what's the FG% of ``Michael Jordan``?\n",
    "\n",
    "    > *Remember, MJ's name in this dataset is ``Michael Jordan*`` because he was (obviously) inducted in the HoF.*\n",
    "\n",
    "    Enter your result with up to three decimal points(don't round-off). That is, if the value is ``0.618324``, enter ``0.618`` (including the ``0`` and the dot `.`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_goal_perc.loc['Michael Jordan*']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Field goals per Game**\n",
    "\n",
    "    Calculate \"Field Goals per Game\" using the series ``field_goals`` and games_played. Store your results in the variable ``field_goals_per_game``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_played.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_goals_per_game = field_goals / games_played "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_goals_per_game.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Which player has the highest 'Field Goal per Game' value?**\n",
    "\n",
    "    All stars here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_goals_per_game.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Calculate 'Total Points'**\n",
    "\n",
    "    In the NBA lingo, field goals account for all the \"goals\" scored by a player, **EXCEPT** free throws. So, if we want to calculate the total number of points scored by a player, we must add field goals and free throws. Field goals are a combination of 2-point and 3-point goals. For this exercise, you can safely assume that all \"field goals\" have a value of 2.\n",
    "\n",
    "    Calculate Total Points scored by a player, by adding the series containing field goals and free throws. Store your results in the variable ``total_points``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_goals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_throws.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_points = (field_goals * 2) + free_throws\n",
    "total_points.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Who's the player with the most Total Points?\n",
    "\n",
    "    Who's the player that, according to our dataset, has scored the most points in the NBA history?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_points.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Total Points per Minute\n",
    "\n",
    "    Using the series that you previously calculated, ``total_points``, calculate \"Total points per minute\". Store your results in the variable ``points_per_minute``.\n",
    "\n",
    "    > *Important. This activity relies on ``total_points``. Make sure you have completed that one correctly.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_per_minute = total_points / minutes_played"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **Who has a better Points per Minute score; MJ or Kevin Durant?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxmax, valmax = points_per_minute.agg(['idxmax', 'max'])\n",
    "print(idxmax, valmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_per_minute.loc['Michael Jordan*'] > points_per_minute.loc['Kevin Durant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **Calculate FT**\n",
    "\n",
    "    FT is the proportion of scored Free Throws divided by the total attempts. Basically, the accuracy of Free Throws. Store your results in ``ft_perc``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_perc = free_throws / free_throws_attempts\n",
    "ft_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Who's the player with best FT% record: MJ or Larry Bird?\n",
    "\n",
    "    A battle of titans. Who had a better FT% record?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_perc.loc['Michael Jordan*'] > ft_perc.loc['Larry Bird*']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. **Find the top 25% players by 'free throw accuracy'**\n",
    "\n",
    "    Create a boolean series that contains ``True`` values for those players that are in the top 25% by free throw efficiency (using the preivously calculated) ``ft_perc`` series. Store your results in the variable ``ft_top_25``.\n",
    "\n",
    "    Your result should look something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_perc.quantile(.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_perc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_top_25 = ft_perc >= ft_perc.quantile(.75)\n",
    "ft_top_25.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_top_25 = ft_perc.where(ft_perc > ft_perc.quantile(.75)) == ft_perc\n",
    "ft_top_25.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. How many players are in the top 25% by free throw accuracy?\n",
    "\n",
    "    Answer using the previously calcualted series ``ft_top_25``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_top_25.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_top_25.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Find those players that scored 0 points in their history\n",
    "\n",
    "    Create a boolean series that contains ``True`` values for those players that have scored 0 total points. Store your results in the variable ``players_0_points``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_0_points = total_points == 0\n",
    "players_0_points.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring DataFrames with Currency Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the project on exploring currency data using pandas DataFrame! In this project, we will embark on an exciting journey of analyzing and gaining insights from a comprehensive dataset containing information about different currencies from around the world.\n",
    "\n",
    "Throughout this project, we will focus on practicing fundamental techniques on pandas DataFrames to extract meaningful information and perform various analyses. We will work with a dataset that includes currency names, symbols, currency codes, countries of usage, and other relevant details.\n",
    "\n",
    "Our exploration will cover several essential topics. Firstly, we will master basic navigation techniques using methods like ``head()``, ``tail()``, ``info()``, ``shape``, ``describe()``, ``nunique()``, and ``isnull()``. These methods will allow us to quickly inspect the dataset, understand its structure, and identify any missing values.\n",
    "\n",
    "Next, we will learn different methods for selecting specific columns from the DataFrame. Using indexing with ``[]``, ``loc[]``, and ``iloc[]``, we will extract and analyze specific attributes of the currencies. This selective approach will enable us to focus on the aspects that interest us the most and perform targeted analyses.\n",
    "\n",
    "Lastly, we will delve into slicing techniques to basic filter the DataFrame. Slicing will allow us to extract subsets of data and perform more detailed and granular analyses. By applying these slicing techniques, we can gain insights into specific groups of currencies or examine currencies based on their properties.\n",
    "\n",
    "Through this project, you will gain hands-on experience with pandas DataFrames and develop a solid foundation in data exploration, manipulation, and analysis. By working with a real-world currency dataset, you will enhance your skills in working with diverse datasets and be well-prepared for future data science projects.\n",
    "\n",
    "Get ready to embark on an exciting journey of exploring currency data with pandas DataFrame. Let's dive in and unlock the insights hidden within the world of currencies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('currencies.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Getting an Overview of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the correct answers for dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Digits'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Symbol'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Get the statistics of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Digits'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Digits'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Count the number of unique currencies in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(df['Code']).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Identify the number of missing values in each column\n",
    "\n",
    "    Write the count of all missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Determine the highest currency number in the dataset\n",
    "\n",
    "    Write answer in the form of a float. For example, if the answer is 98, write 98.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Select Currency Names\n",
    "\n",
    "    Extract the ``'Name'`` column from the DataFrame df and assign it to a new variable ``names``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Get the details of the 3rd row\n",
    "\n",
    "    Extract the 3rd row from the DataFrame ``df`` and assign it to a new variable ``row_3``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_3 = df.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Select rows 10 to 15 (inclusive) from the DataFrame\n",
    "\n",
    "    Select rows 10 to 15 (inclusive) from the DataFrame ``df`` and assign it to a new variable ``rows``.\n",
    "\n",
    "    > *You were asked for rows, not index numbers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df.iloc[9:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Extract Alternating Rows from DataFrame\n",
    "\n",
    "    Your task is to extract the alternating rows from the DataFrame df, where \"alternating\" refers to the 1st, 3rd, 5th, and so on (not based on index order). Store these selected rows in a new variable named ``rows_every_other``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_every_other = df.iloc[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_every_other = df.iloc[range(0, len(df), 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Select columns with indices 2, 4, and 5 from the DataFrame\n",
    "\n",
    "    Select columns with indices 2, 4, and 5 from the DataFrame ``df`` and assign it to a new variable ``cols``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.iloc[:,[2,4,5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Select the first three columns of the dataframe\n",
    "\n",
    "    Select the first three columns of the dataframe ``df`` and assign it to a new variable ``cols_first_three``.\n",
    "\n",
    "    > *Dataframe columns also include ``index column``.*\n",
    "\n",
    "    The expected output looks like this (it contains more rows than below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_first_three = df.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Pandas DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a data frame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply put, DataFrames are Python's way of displaying data in tablular form.\n",
    "\n",
    "By using Python's powerful library for Data Analysis - pandas with DataFrames it offers us as users an efficient way to work with large amounts of structured data.\n",
    "\n",
    "Is it similar to Excel?\n",
    "\n",
    "Just as Excel use spreadsheets, Python uses pandas dataframes.\n",
    "\n",
    "> **Python is often preferred over Excel due to its scalability and speed.**\n",
    "\n",
    "#### How is a DataFrame composed?\n",
    "\n",
    "So what does a DataFrame look like? It is made up of rows and columns making it two dimensional. Let's take a look below:\n",
    "\n",
    "We see that our Index is made up of the companies, however an index can also be made up of numbers.\n",
    "\n",
    "> **An ``Index`` is like an address, it can be used to locate both rows and columns.**\n",
    "\n",
    "More on that later.\n",
    "\n",
    "**So, let's jump into our Jupyter notebook and create the DataFrame from this example.**\n",
    "\n",
    "The dataset for today's lab contains information on the Top Tech Companies in the World as shown below:\n",
    "\n",
    "Our DataFrame contains five columns: - ``Revenue`` - ``Employees`` - ``Sector`` - ``Founding`` ``Date`` - ``Country``\n",
    "\n",
    "The syntax to create a dataframe is:\n",
    "\n",
    "```py\n",
    "import pandas as pd\n",
    "pd.DataFrame(data, index)\n",
    "```\n",
    "\n",
    "- **data**: These are the values from our dataset.\n",
    "- **index**: This is like the address of the data we are storing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Navigation & Browsing Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how do we truely harness the power of pandas DataFrames?\n",
    "\n",
    "Let's explore some functions:\n",
    "\n",
    "### head\n",
    "\n",
    "The ``head()`` method displays the first few rows of your DataFrame, making it easier to get a sense of the overall structure and content. It will display the first five rows by default.\n",
    "\n",
    "```py\n",
    "df.head()\n",
    "```\n",
    "\n",
    "We can expand our dataset further and specify the number of rows ``.head(n)`` within the brackets, as shown below:\n",
    "\n",
    "```py\n",
    "df.head(10)\n",
    "```\n",
    "\n",
    "This function is especially useful as you can quickly inspect your DataFrame using the ``head()`` method to ensure that all of the data is stored correctly and as expected.\n",
    "\n",
    "### tail\n",
    "\n",
    "The ``tail()`` method is similar to ``head()`` except it displays the last few rows of your DataFrame.\n",
    "\n",
    "```py\n",
    "df.tail()\n",
    "```\n",
    "Also similar to the ``head()`` we can specify the number of rows we want to display with ``.tail(n)``.\n",
    "\n",
    "```py\n",
    "df.tail(10)\n",
    "```\n",
    "\n",
    "This is useful for quickly identifying any problems with your dataset, as any errors will most likely be found at the end rather than the beginning.\n",
    "\n",
    "### info\n",
    "\n",
    "The ``info()`` method returns a list of all the columns in your DataFrame, along with their names, data types, number of values, and memory usage.\n",
    "\n",
    "```py\n",
    "df.info()\n",
    "```\n",
    "\n",
    "This makes it easy to gain insight into how much space is being taken up by each column and can help identify potential problems such as missing values or incorrect data types.\n",
    "\n",
    "### shape\n",
    "\n",
    "The shape method returns a tuple with the number of rows and columns (rows, columns) in our DataFrame.\n",
    "\n",
    "```py\n",
    "df.shape\n",
    "```\n",
    "\n",
    "This gives us a quick insight into the dimensionality of our DataFrame.\n",
    "\n",
    "### describe\n",
    "\n",
    "The ``describe()`` method displays descriptive statistics for numerical columns in your DataFrame, including the mean, median, standard deviation, minimum and maximum values.\n",
    "\n",
    "```py\n",
    "df.describe()\n",
    "```\n",
    "\n",
    "This can be very useful for understanding the distribution of values across a specific dataset or column without having to manually calculate each statistic.\n",
    "\n",
    "### nunique\n",
    "\n",
    "The ``nunique()`` method counts the number of distinct elements.\n",
    "\n",
    "```py\n",
    "df.nunique()\n",
    "```\n",
    "\n",
    "This can be very useful for understanding the number of categories we have in a column for example.\n",
    "\n",
    "### isnull\n",
    "\n",
    "The ``isnull()`` method detected missing values by creating a DataFrame object with a boolean value of ``True`` for ``NULL`` values and otherwise ``False``.\n",
    "\n",
    "```py\n",
    "df.isnull()\n",
    "```\n",
    "\n",
    "We can take this one step further by applying the ``sum()`` function to get a total number of ``NULL`` values in our DataFrame.\n",
    "\n",
    "```py\n",
    "df.isnull().sum()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin this section it is important we can differenciate between a Series and a ``DataFrame``.\n",
    "\n",
    "- A ``Series`` is a single column in a DataFrame\n",
    "- A ``DataFrame`` is an entire table of data.\n",
    "\n",
    "Let's take a look at how we can choose these items:\n",
    "\n",
    "### Select One Column\n",
    "\n",
    "The ``[]`` operator can be used to select a specific column within a DataFrame. The output is a ``Series``.\n",
    "\n",
    "```py\n",
    "df['column_name']\n",
    "```\n",
    "\n",
    "### Select One Column and Apply Methods\n",
    "\n",
    "DataFrame's also allow the user to apply methods on columns, these functions include ``sum()``, ``mean()``, ``min()``, ``max()``, ``median()`` and more.\n",
    "\n",
    "```py\n",
    "df['column_name'].sum()\n",
    "```\n",
    "\n",
    "### Select Multiple Columns\n",
    "\n",
    "To select multiple columns, use the ``[]`` operator with a ``list`` of column names as the argument. This creates another ``DataFrame``.\n",
    "\n",
    "```py\n",
    "df[['column_name_1', 'column_name_2','column_name_3']]\n",
    "```\n",
    "\n",
    "We can save this new DataFrame under a new variable name so that we can come back to it later.\n",
    "\n",
    "```py\n",
    "new_df = df[['column_name_1', 'column_name_2','column_name_3']]\n",
    "```\n",
    "\n",
    "### Select Multiple Columns and Apply Methods\n",
    "\n",
    "We can take a shortcut and apply methods on more than one column at the same time.\n",
    "\n",
    "```py\n",
    "df[['column_name_1', 'column_name_2','column_name_3']].mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of data\n",
    "data = {'Revenue': [274515,200734,182527,181945,143015,129184,92224,85965,84893,\n",
    "                    82345,77867,73620,69864,63191],\n",
    "        'Employees': [147000,267937,135301,878429,163000,197000,158000,58604,\n",
    "                      109700,350864,110600,364800,85858,243540],\n",
    "        'Sector': ['Consumer Electronics','Consumer Electronics','Software Services',\n",
    "                   'Chip Manufacturing','Software Services','Consumer Electronics',\n",
    "                   'Consumer Electronics','Software Services','Consumer Electronics',\n",
    "                   'Consumer Electronics','Chip Manufacturing','Software Services',\n",
    "                   'Software Services','Consumer Electronics'],\n",
    "        'Founding Date':['01-04-1976','13-01-1969','04-09-1998','20-02-1974',\n",
    "                         '04-04-1975','15-09-1987','01-02-1984','04-02-2004',\n",
    "                         '07-04-1946','01-01-1910','18-07-1968','16-06-1911',\n",
    "                         '11-11-1998','07-03-1918'],\n",
    "        'Country':['USA','South Korea','USA','Taiwan','USA','China','USA','USA',\n",
    "                   'Japan','Japan','USA','USA','China','Japan']} \n",
    "index = ['Apple','Samsung','Alphabet','Foxconn','Microsoft','Huawei',\n",
    "         'Dell Technologies','Meta','Sony','Hitachi','Intel','IBM',\n",
    "         'Tencent','Panasonic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Output the first four rows of the df using the head function\n",
    "\n",
    "    Now it's your turn! Try outputting the first four rows of the dataframe using the head function. Store the result in the variable ``head_first_4``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_first_4 = df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Output the last six rows of the df using the tail function.\n",
    "\n",
    "    Now try output the last six rows of the dataframe using the tail function. Store the result in the variable ``tail_last_6``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_last_6 = df.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Select the column Employees\n",
    "\n",
    "    Let's practice these skills, select the column ``Employees`` into the variable ``employees_s``. You'll notice that the result of this selection is a ``Series``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_d = df['Employees']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Output the median Employees to the nearest whole number\n",
    "\n",
    "    Now, take it one step further and find the median of each row for the column ``Employees``. Store the result in the variable ``employees_median``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_median = df['Employees'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculate the mean for columns Revenue and Employees\n",
    "\n",
    "    Lastly, let's calculate the mean for the columns ``Revenue`` and ``Employees``. Store the result in the variable ``r_e_mean``.\n",
    "\n",
    "    Your result should be a Series, and it should look something like:\n",
    "\n",
    "    ```py\n",
    "    Revenue      XXX\n",
    "    Employees    YYY\n",
    "    dtype: float64\n",
    "    ```\n",
    "\n",
    "    > *Round off the mean to the nearest whole number.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_e_mean = df[['Revenue', 'Employees']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_e_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection by Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by Index - ``loc``\n",
    "\n",
    "Index selection ``.loc`` is a Python DataFrames method that allows users to select DataFrame rows and columns by their **labels or integer positions**.\n",
    "\n",
    "> ***It is most commonly used when a user needs to access specific elements within a DataFrame, such as selecting all rows with a specific label or values in a specific column.***\n",
    "\n",
    "```py\n",
    "df.loc[row_label, column_label]\n",
    "```\n",
    "\n",
    "We can use ``:`` in place of ``row_label`` or ``column_label`` to call all the data.\n",
    "\n",
    "```py\n",
    "df.loc[:, column_label]\n",
    "df.loc[row_label,:]\n",
    "```\n",
    "\n",
    "We can also pass multiple columns in place of ``column_label`` or multiple rows in place of ``row_label``.\n",
    "\n",
    "```py\n",
    "df.loc[['row_name_1', 'row_name_2','row_name_3'], column_label]\n",
    "df.loc[row_label,['column_name_1', 'column_name_2','column_name_3']]\n",
    "```\n",
    "\n",
    "Slicing is a powerful feature of pandas that enables us to access specific parts of our DataFrame.\n",
    "\n",
    "> ``start:stop:step``\n",
    "\n",
    "If we don't specify the step, the default value is 1.\n",
    "\n",
    "### With column's\n",
    "```py\n",
    "df.loc[`row_label`, `column_name_start`:`column_name_stop`]\n",
    "```\n",
    "### With rows's\n",
    "```py\n",
    "df.loc[`row_name_start`:`row_name_stop` , `column_label`]\n",
    "```\n",
    "### With step\n",
    "```py\n",
    "df.loc[`row_label`, `column_name_start`:`column_name_stop`:n]\n",
    "\n",
    "df.loc[`row_name_start`:`row_name_stop`:n , `column_label`]\n",
    "```\n",
    "### With step and :\n",
    "```py\n",
    "df.loc[:`, `column_name_start`:`column_name_stop`:n]\n",
    "\n",
    "df.loc[`row_name_start`:`row_name_stop`:n , :]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the revenue for Samsung \n",
    "\n",
    "# loc[row_label, column_label]\n",
    "\n",
    "df.loc['Samsung','Revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc[row_label, column_label]\n",
    "\n",
    "df.loc[:,'Revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_label\n",
    "df.loc['Samsung',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_label\n",
    "df.loc[:, 'Revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple columns\n",
    "df.loc[['Apple','Samsung','Sony'], 'Revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple rows\n",
    "df.loc['Apple', ['Employees','Country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = ['Apple','Samsung','Sony']\n",
    "columns = ['Employees','Sector','Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc[row_label, column_label]\n",
    "\n",
    "df.loc[rows,columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing ``start:stop:step``\n",
    "\n",
    "With columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Apple', 'Employees':'Founding Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ``rows``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Apple':'Sony', 'Employees']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ``step``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Apple':'Sony':2, columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ``step`` and ``:``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Apple':'Sony':2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Select the Revenue, Employees & Sector for the companies Apple, Alphabet and Microsoft\n",
    "\n",
    "    Now let's leverage your ``.loc`` selection skills. Your task is to select the columns ``Revenue``, ``Employees`` & ``Sector`` for the companies Apple, Alphabet and Microsoft. Your result should be stored in a variable ``index_selection`` and it should be a DataFrame looking something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_selection = df.loc[['Apple','Alphabet','Microsoft'],['Revenue','Employees','Sector']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection by Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection by position ``.iloc`` is a useful Python DataFrames method that allows users to select rows and columns of a DataFrame **based on their integer positions**.\n",
    "\n",
    "> ***This is especially useful when users need to access elements within a DataFrame that do not have labels or specific column names.***\n",
    "\n",
    "```py\n",
    "df.iloc[row_position, column_position]\n",
    "```\n",
    "\n",
    "We can use ``:`` in place of ``row_position`` or ``column_position`` to call all the data.\n",
    "\n",
    "```py\n",
    "df.iloc[:, column_position]\n",
    "\n",
    "df.iloc[row_position,:]\n",
    "```\n",
    "\n",
    "We can also pass multiple columns in place of ``column_position`` or multiple rows in place of ``row_position``.\n",
    "\n",
    "```py\n",
    "df.iloc[['row_position_1', 'row_position_2','row_position_3'], column_position]\n",
    "\n",
    "df.iloc[row_position,['column_position_1', 'column_position_2','column_position_3']]\n",
    "```\n",
    "\n",
    "**Slicing** is a powerful feature of pandas that enables us to access specific parts of our ``DataFrame``.\n",
    "\n",
    "> ``start:stop:step``\n",
    "\n",
    "### With column's\n",
    "```py\n",
    "df.iloc[`row_position`, `column_position_start`:`column_position_stop`]\n",
    "```\n",
    "\n",
    "### With rows's\n",
    "```py\n",
    "df.iloc[`row_position_start`:`row_position_stop` , `column_position`]\n",
    "```\n",
    "\n",
    "### With step\n",
    "```py\n",
    "df.iloc[`row_position`, `column_position_start`:`column_position_stop`:n]\n",
    "\n",
    "df.iloc[`row_position_start`:`row_position_stop`:n , `column_position`]\n",
    "```\n",
    "\n",
    "### With step and :\n",
    "```py\n",
    "df.iloc[:`, `column_position_start`:`column_position_stop`:n]\n",
    "\n",
    "df.iloc[`row_position_start`:`row_position_stop`:n , :]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the revenue for Samsung \n",
    "df.iloc[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice if we use ``:`` in place of ``row_position``, it will again return all the data from the specified column.\n",
    "\n",
    "Thus, we have a ``Series``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use ``:`` in place of ``row_position`` or ``column_position``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_position\n",
    "df.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_position\n",
    "df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select a ``list`` of values this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple columns\n",
    "df.iloc[[0,1,8], 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple rows\n",
    "df.iloc[0, [1,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_i = [0,1,8]\n",
    "columns_i = [1,2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[rows_i,columns_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing start:stop:step:\n",
    "\n",
    "### With columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0, 1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:8, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:9:2, columns_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ``step`` & ``:``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:9:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. ***Using Position Selection, select the Revenue, Employees & Country for the companies ``Samsung``, ``Foxconn`` and ``Huawei``.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[1,3,5],[0,1,4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mastering DataFrame Mutations with Hollywood data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll engage with an actual dataset, applying various data manipulation techniques. Our focus will be a movie dataset, including information like the film title, release year, budget, gross earnings, and more.\n",
    "\n",
    "This lab will cover the following:\n",
    "\n",
    "- Creating new columns in a data frame by doing basic arithmetic operations (addition, subtraction, division) on existing columns.\n",
    "- Creating new columns in a data frame by applying boolean operations (less-than ``<``, greater-than ``>``, equals ``==``, etc.) on existing columns.\n",
    "- Deleting rows based on specific conditions.\n",
    "- Removing single or multiple columns based on conditions.\n",
    "\n",
    "Let's start by loading our dataset.\n",
    "\n",
    "You can do this by using the ``pandas.read_csv()`` function to load the dataset into a pandas dataframe. Afterwards, store the dataframe in a variable named ``df``.\n",
    "\n",
    "Here is a sample code:\n",
    "\n",
    "```py\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"movies.csv\")\n",
    "df\n",
    "```\n",
    "\n",
    "> ***IMPORTANT NOTE: Please ensure you complete all activities in the lab in sequence. Each activity builds on the one before it, so skipping an activity will prevent further progress. Complete each task fully before moving on to the next for a successful learning experience.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Create a new column ``revenue``**\n",
    "\n",
    "    Add a new column named ``revenue`` to the dataframe ``df``. This new column should reflect the difference between the values in the ``gross`` and ``budget`` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['revenue'] = df['gross'] - df['budget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  **Create a new column ``percentage_profit``**\n",
    "\n",
    "    Create a new column called ``percentage_profit``. You will calculate its values as the proportion of the gross earnings out of the total revenue for each row. For example, if the gross earning is 100 million out of a total revenue of 200 million, the ``percentage_profit`` will be 50%.\n",
    "\n",
    "    - Express profit percentage as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['percentage_profit'] = df['revenue']/df['gross']*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Create a new column ``high_budget_movie``**\n",
    "\n",
    "    Add a new column named ``high_budget_movie`` to dataframe ``df``. This column should label each movie with ``True`` if it has a budget over 100 million, or ``False`` if it does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['high_budget_movie'] = df['budget'] > 100_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Create a new column ``successful_movie``**\n",
    "\n",
    "    Add a new column named ``successful_movie``. Assign it the value ``True`` if a movie's ``percentage_profit`` exceeds 50. If it doesn't, assign ``False``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['successful_movie'] = df['percentage_profit'] > 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **High-Rated Movies**\n",
    "\n",
    "    Create a new column called ``high_rated_movie``. If the movie's ``score`` is more than 8, label it as ``True``. If not, label it as ``False``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['high_rated_movie'] = df['score'] > 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Create a new column ``is_new_release``**\n",
    "\n",
    "Create a new column named ``is_new_release``. This column should indicate ``True`` if the year column's value is beyond 2020, and ``False`` if it's not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_new_release'] = df['year'] > 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **Create a new column ``is_long_movie``**\n",
    "\n",
    "    Create a new column ``is_long_movie`` which is True if the value of runtime column is greater than 150 minutes and ``False`` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_long_movie'] = df['runtime'] > 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **Drop unsuccessful movie**\n",
    "\n",
    "    Delete all rows in the dataframe df where the column ``successful_movie`` is labeled as ``False``. Use the inplace attribute to make sure these modifications are permanent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"successful_movie\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df['successful_movie'] == False].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **Drop high budget movie**\n",
    "\n",
    "    Create a new dataframe named ``low_budget_df`` by removing all rows from the original dataframe where the ``budget`` value exceeds 100 million. Remember, changes shouldn't affect the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_budget_df = df[df['budget']<100_000_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Removing Low-Voted Movies\n",
    "\n",
    "    Remove all the rows from the dataframe where the ``votes`` count is below ``1000``. Assign this updated dataframe to a new variable named ``high_voted_df``. Ensure you do not make these changes to the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_voted_df = df[df['votes']>1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. **Drop the column ``budget``**\n",
    "\n",
    "    To delete the ``budget`` column from the movie dataframe, apply the drop method and include the column's name, ``budget``. Make sure to specify the axis to show you're referring to a column, not a row. Also, set the inplace ``parameter`` to ``True`` so the change isn't temporary but permanent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['budget'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Drop the director and writer columns from the dataframe.\n",
    "\n",
    "    Remove the ``director`` and ``writer`` columns from the dataframe ``df``. To do this, employ the drop method, designating ``director`` and ``writer`` as the column names. Set the axis to confirm that these are columns not rows. Make sure to adjust the ``inplace`` parameter to ``False``, this way you're forming a new dataframe named ``new_df`` without altering the original one.\n",
    "\n",
    "    Please remember, in this activity, your task is to build a new dataframe named ``new_df``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.drop(['director', 'writer'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.drop(columns=['director','writer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Drop Out Low-Rated and Low-Voted Movies\n",
    "\n",
    "    Drop all the rows where the value of score is less than ``5`` and the value of votes is less than ``1000``. Drop the rows from the original dataframe ``df``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_low = df.loc[(df['score'] < 5) & (df['votes'] < 1000) ]\n",
    "df.drop(index_low.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. **Top High-Rated Movies**\n",
    "\n",
    "    Create a new DataFrame named ``top_rated_movies``, which should include the top five highly-rated movies. Sort this DataFrame based on the ``score`` column in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_rated_movies = df.sort_values(ascending=False, by=['score'])[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_rated_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Removing Specific Rows\n",
    "\n",
    "    Remove rows with index ``2`` and ``10`` from the DataFrame ``df``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([2,10], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Sci-Fi Blockbusters\n",
    "\n",
    "    Create a new DataFrame named ``sci_fi_blockbusters`` containing movies that are 'Sci-Fi' genre and have a gross greater than $150 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_fi_blockbusters = df[(df['genre'] == 'Sci-Fi') & (df['gross'] > 150_000_000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. **Age of Movies**\n",
    "\n",
    "    Create a new column named ``age`` to calculate the age of the movie in years. Find it by subtracting the ``year`` column from the current year.\n",
    "\n",
    "    Consider 2023 as the current year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = 2023 - df['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. **Movies Released in Summer**\n",
    "\n",
    "    Create a new DataFrame containing movies released in June, July, or August. Store the result in dataframe ``summer_movies``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_movies = df[(df['released'].str.contains('June')) | (df['released'].str.contains('July')) | (df['released'].str.contains('August'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying DataFrames: Creating columns and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we'll cover the most common types of operations to \"modify\" dataframes. This includes:\n",
    "\n",
    "- Creating new columns\n",
    "- Deletion: deleting rows or columns\n",
    "- Modifications: renaming columns, changing column types, modifying values\n",
    "- Adding new rows\n",
    "\n",
    "In the process, we'll also learn the important concepts of mutability/immutability and how to perform a \"safe\" Data Science workflow (spoiler: by avoiding modifications!)\n",
    "\n",
    "> ***IMPORTANT NOTE: If you accidentally made incorrect modifications to the dataframe in this lab, you will need to redo all the previous steps in order to successfully complete the activity.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with one of the most straightforward operations: creating new columns. We can create new columns in multiple ways, but let's start with the most common one:\n",
    "\n",
    "### Expressions (and vectorized operations)\n",
    "\n",
    "The most common way to create a column is just as the result of an expression of other columns within the same DataFrame. If you're familiar with spreadsheets, this is a simple operation:\n",
    "\n",
    "The syntax is extremely intuitive, it's just assigning \"the new column\" to a given expression:\n",
    "\n",
    "```py\n",
    "df[\"New Column Name\"] = [EXPRESSION]\n",
    "```\n",
    "In this case, the expression can be anything. Examples:\n",
    "\n",
    "```py\n",
    "# A  simple arithmetic expression between two columns\n",
    "df[\"New Column Name\"] = df[\"Column 1\"] + df[\"Column 2\"]\n",
    "\n",
    "# A boolean expression\n",
    "df[\"New Column Name\"] = df[\"Column 1\"] > 1000\n",
    "\n",
    "# A more advanced expression multiple columns\n",
    "df[\"New Column Name\"] = df[\"Column 1\"] * (df[\"Column 2\"] / df[\"Column 3\"]) / df[\"Column 4\"].std\n",
    "```\n",
    "\n",
    "Let's use our sample DataFrame to calculate \"Revenue per Employee\" (as in the GIF above). The expression is just:\n",
    "\n",
    "```py\n",
    "df[\"Revenue per Employee\"] = df[\"Revenue\"] / df[\"Employees\"]\n",
    "```\n",
    "\n",
    "We call these expressions \"vectorized operations\", as they act upon the whole dataframe, regardless if it has 100 rows, or 1 billion. Vectorized Operations are extremely fast, even with large number of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of data\n",
    "data = {'Revenue': [274515,200734,182527,181945,143015,129184,92224,85965,84893,\n",
    "                    82345,77867,73620,69864,63191],\n",
    "        'Employees': [147000,267937,135301,878429,163000,197000,158000,58604,\n",
    "                      109700,350864,110600,364800,85858,243540],\n",
    "        'Sector': ['Consumer Electronics','Consumer Electronics','Software Services',\n",
    "                   'Chip Manufacturing','Software Services','Consumer Electronics',\n",
    "                   'Consumer Electronics','Software Services','Consumer Electronics',\n",
    "                   'Consumer Electronics','Chip Manufacturing','Software Services',\n",
    "                   'Software Services','Consumer Electronics'],\n",
    "        'Founding Date':['01-04-1976','13-01-1969','04-09-1998','20-02-1974',\n",
    "                         '04-04-1975','15-09-1987','01-02-1984','04-02-2004',\n",
    "                         '07-04-1946','01-01-1910','18-07-1968','16-06-1911',\n",
    "                         '11-11-1998','07-03-1918'],\n",
    "        'Country':['USA','South Korea','USA','Taiwan','USA','China','USA','USA',\n",
    "                   'Japan','Japan','USA','USA','China','Japan']} \n",
    "index = ['Apple','Samsung','Alphabet','Foxconn','Microsoft','Huawei',\n",
    "         'Dell Technologies','Meta','Sony','Hitachi','Intel','IBM',\n",
    "         'Tencent','Panasonic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Revenue per Employee\"] = df[\"Revenue\"] / df[\"Employees\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Creating a new column**\n",
    "\n",
    "    The column ``Revenue`` is expressed in *millions of dollars*. Create a new one, ``Revenue in $`` with the values for revenue expressed in $US Dollars (single units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Revenue in $'] = df['Revenue']*1_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Create a new column: ``Is American?``**\n",
    "\n",
    "    Create a new boolean column ``Is American?`` that contains the value ``True`` for companies which Country is USA, and ``False`` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Is American?'] = df['Country'] == 'USA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Columns out of Fixed Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single (hardcoded) value\n",
    "\n",
    "We can create columns by also providing values directly. In its simplest form, we just assign the new column to a hardcoded value:\n",
    "\n",
    "```py\n",
    "df[\"New Column\"] = VALUE\n",
    "```\n",
    "\n",
    "This will set EVERY rows in the dataframe with that given value. In our notebook, we're setting the value ``Is Tech?`` to \"Yes\".\n",
    "\n",
    "### Collection of values\n",
    "\n",
    "Instead of providing just one value for the entire dataframe (and for every single row), we can provide a more \"granular\" collection containing the value for each row we want to assign.\n",
    "\n",
    "Let's look at the example in the associated notebook. In the variable ``stock_prices`` we're storing the stock prices of the given companies. We'll then assign the values to the column ``\"Stock Price\"`` directly:\n",
    "\n",
    "```py\n",
    "stock_prices = [143.28, 49.87, 88.26, 1.83, 253.75, 0,\n",
    "                43.4, 167.32, 89.1, 52.6, 25.58, 137.35, 48.23, 8.81]\n",
    "\n",
    "df['Stock Price'] = stock_prices\n",
    "```\n",
    "\n",
    "This works because the list ``stock_prices`` contains the same number of elements as in the DataFrame.\n",
    "\n",
    "> ***Note: The stock prices here are estimate. Not all companies are listed in the same exchange, so we just estimated the value in dollars. Also, ``Huawei`` is not publicly listed, so we assigned a value of $0.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Is Tech?'] = \"Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices = [143.28, 49.87, 88.26, 1.83, 253.75, 0,\n",
    "                43.4, 167.32, 89.1, 52.6, 25.58, 137.35, 48.23, 8.81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Stock Price'] = stock_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a new column with the CEOs of each company\n",
    "\n",
    "    Create new column ``CEO`` that contains the names of the CEOs of each company. You'll find the list of the CEOs in the associated notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ceo_list = [\n",
    "    \"Tim Cook\", \"Kim Ki Nam\", \"Sundar Pichai\",\n",
    "    \"Young Liu\", \"Satya Nadella\", \"Ren Zhengfei\",\n",
    "    \"Michael Dell\", \"Mark Zuckerberg\",\n",
    "    \"Kenichiro Yoshida\", \"Toshiaki Higashihara\", \"Patrick Gelsinger\",\n",
    "    \"Arvind Krishna\", \"Ma Huateng\", \"Yuki Kusumi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CEO'] = ceo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting Columns with `del`\n",
    "\n",
    "There are mainly two ways of deleting columns, using the ``del`` keyword and with the drop method. For now we'll focus only on the del keyword as the drop method introduces a few more complexities that we'll need to address later.\n",
    "\n",
    "The ``del`` keyword is the simplest and most intuitive expression, just: ``del df[\"Column Name\"]``. It will modify the underlying dataframe, so use it carefully!\n",
    "\n",
    "For example, let's delete the column Is Tech? that we created before.\n",
    "```py\n",
    "del df[\"Is Tech?\"]\n",
    "```\n",
    "Take a look now at the dataframe and see the column is no longer there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Delete the column CEO\n",
    "\n",
    "    Using the ``del`` keyword, delete the column ``CEO``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['CEO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutability and Immutability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a **VERY important** concept in Data Science (and programming in general). When solving problems, we usually have the option to resolve them with a \"mutable\" solution, that is, modifying (or *mutating*) the underlying dataframe, or with an *immutable* solution, which performs the changes but without modifying the underlying data.\n",
    "\n",
    "For example, most of the String methods in Python are **immutable**. You can perform a wide variety of operations (``replace``, ``title``, ``upper``, ``lower``, etc) but the original string is NOT modified, these operations return NEW strings (new copies) with the desired changes applied. Take a look at the notebook for a few of these strings examples and pay attention at how the string ``s`` is not modified after any of the operations.\n",
    "\n",
    "### Favor Immutability`\n",
    "\n",
    "Python's decision for strings (and other, non mentioned modules) is not a coincidence. Most of the time (and only under rare exceptions), we **should prefer immutable solutions**. Specially in Pandas, operations that don't modify the underlying DataFrames or Series. That way, you can always safely try things without the risk of losing important data.\n",
    "\n",
    "Here's an example of the flow you should expect when performing immutable operations (don't worry about the methods below, we'll learn about them in this and other projects):\n",
    "\n",
    "```py\n",
    "df = df.read_csv()\n",
    "df_renamed = df.rename(...) # rename columns\n",
    "df_notna = df_renamed.dropna(...)  # dropping null values\n",
    "df_cleaned = df_notna.drop(...)  # dropping some values\n",
    "```\n",
    "\n",
    "As you can see, the result of each operation is the \"entry point\" of the following operation, creating a chain. This is intentional, because, as you'll see, we'll use this \"chaining\" to our advantage. It's pretty common to see expressions that are a combination (chaining) of multiple methods one after the other:\n",
    "\n",
    "```py\n",
    "df.dropna().drop([...]).rename([...]).sort_values().head()\n",
    "```\n",
    "\n",
    "### The ``inplace`` parameter\n",
    "\n",
    "Before moving forward, we need to make a special mention about the inplace parameter.\n",
    "\n",
    "The ``inplace`` parameter is EVERYWHERE in pandas methods, both for DataFrames and Series. For example, ``df.dropna(inplace=True)``, ``df.drop([...], inplace=True)``, ``df.drop_duplicates(inplace=True)``, etc.\n",
    "\n",
    "The inplace parameter changes the behavior of a given method from immutable (default) to mutable, modifying the underlying DataFrame. Again, by default, ``inplace`` is always ``False``, as Pandas is always favoring immutability. You can alter that behavior by setting ``inplace=True``, although, as we just mentioned, it's NOT recommended, except in some special cases.\n",
    "\n",
    "Now, let's move to the next section to put these concepts to use!\n",
    "\n",
    "## Deleting rows\n",
    "\n",
    "The method to delete \"arbitrary\" rows is: ``.drop``. It has some variations, as it can also be used to delete columns, but let's start with the basics.\n",
    "\n",
    "The ``.drop()`` method accepts the indices of the values we want to remove, and as we previously mentioned, by default, is **immutable**.\n",
    "\n",
    "In the notebook you can see an example of deleting multiple rows:\n",
    "\n",
    "```py\n",
    "df.drop([\"Microsoft\", \"Tencent\", \"Samsung\", \"Alphabet\", \"Meta\", \"Hitachi\", \"Apple\"])\n",
    "```\n",
    "\n",
    "Again, this method **is IMMUTABLE**. It doesn't modify the underlying dataframe: it immediately returns a new DataFrame with the modifications done. The common pattern is to assign the results of ``.drop`` to a variable: ``df_new = df.drop(...)``. This allows us to re-play any operation if we find a mistake in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Drop Microsoft from the df\n",
    "\n",
    "    Using ``.drop``, delete ``Microsoft`` and assign the result to ``df_no_windows``. IMPORTANT, you should NOT modify ``df``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_windows = df.drop('Microsoft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_windows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutable modification with ``inplace``\n",
    "\n",
    "We have iterated and reiterated the importance of favoring immutable solutions. But still, we need to cover how to perform mutable solutions. Just remember, use mutability as spare as possible.\n",
    "\n",
    "As we've mentioned, most pandas operations accept the ``inplace`` parameter, which, when passed a ``True`` value, will perform such operation modifying the underlying DataFrame. We'll do it now with the .``drop()`` parameter. Switch to the notebook to see how we're deleting the value for Huawei:\n",
    "\n",
    "```py\n",
    "df.drop(\"Huawei\", inplace=True)\n",
    "```\n",
    "\n",
    "As you can see, the method doesn't return anything (just ``None``). It doesn't provide a result, as the result of the operation, is already applied to the underlying DataFrame. Check again the ``df`` to see that we have correctly deleted ``Huawei`` from the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Delete ``inplace`` the values for ``IBM`` and ``Dell``\n",
    "    \n",
    "    Perform a mutable operation and delete the rows containing information for ``IBM`` and ``Dell Technologies``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['IBM','Dell Technologies'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting rows based on a condition\n",
    "\n",
    "Deleting rows based on a condition is simple, as we'll just use the same ``.drop()`` method as before. What might be a little bit more \"complicated\" is the final syntax that will result from writing these conditions.\n",
    "\n",
    "First all, remember that the ``.drop()`` method receives the index of the values we want to delete. Let's say we want to delete the companies with Revenue of LESS than ``M$80,000``. Those companies are ``Intel``, ``Tencent`` and ``Panasonic``. So, we have to finally arrive to an expression that is equivalent to:\n",
    "```py\n",
    "df.drop([\"Intel\", \"Tencent\", \"Panasonic\"])\n",
    "```\n",
    "\n",
    "How do we do that with conditions? It involves two steps:\n",
    "\n",
    "First, let's write the condition:\n",
    "```py\n",
    "df.loc[df[\"Revenue\"] < 80_000]\n",
    "```\n",
    "But then, we need the index for the result of that condition. So we append the .index to the end of the condition. So, the final expression ends up being:\n",
    "```py\n",
    "df.drop(df.loc[df[\"Revenue\"] < 80_000].index)\n",
    "```\n",
    "That, as we said before, is not the most pleasing syntactical experience.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Delete companies with revenue lower than the mean\n",
    "\n",
    "    Drop the companies that have a value of ``Revenue`` lower than the mean (average ``Revenue``). Do NOT modify the original DataFrame; store the new results in ``df_high_revenue``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Revenue'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_revenue = df.drop(df.loc[df['Revenue'] < df['Revenue'].mean()].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Drop the companies that are NOT from the ``USA``\n",
    "\n",
    "    Drop the companies whose country is NOT ``USA``. Store the results in the variable ``df_usa_only``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usa_only = df.drop(df.loc[~df['Is American?']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usa_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Japanese companies sorted by Revenue (desc)\n",
    "\n",
    "    Using chaining methods, perform the following two operations in the same expression: * drop all the companies that are NOT Japanese * sort them by Revenue in descending order\n",
    "\n",
    "    Store your results in the variable ``df_jp_desc``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jp_desc = df.drop(df.loc[df['Country'] != 'Japan'].index).sort_values(by ='Revenue' ,ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jp_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing columns with ``.drop()``\n",
    "\n",
    "Finally, it's worth mentioning that the ``.drop()`` method can be used to delete columns as well, as an immutable alternative to ``del``. The syntax is the same as removing rows, but to indicate that we want to delete columns, we must pass ``axis=1`` as a parameter. By default, the axis parameter is ``0``, which means \"delete at row level\"; by setting it to ``1`` we're indicating we're deleting columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Revenue', 'Employees'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring DataFrames with Pokemon Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we'll explore the basics of DataFrames using a Dataset containing Pokemon information.\n",
    "\n",
    "We'll start by reading the dataset using the ``pd.read_csv()`` method.\n",
    "\n",
    "Then, the ``df.head()`` and ``df.info()`` methods gives us a bit more information about the underlying data.\n",
    "\n",
    "Play around with it and once you're ready, jump to the next page to complete the activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pokemon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Charmeleon</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #        Name Type 1  Type 2  Total  HP  Attack  Defense  Sp. Atk  Sp. Def  \\\n",
       "0  1   Bulbasaur  Grass  Poison    318  45      49       49       65       65   \n",
       "1  2     Ivysaur  Grass  Poison    405  60      62       63       80       80   \n",
       "2  3    Venusaur  Grass  Poison    525  80      82       83      100      100   \n",
       "3  4  Charmander   Fire     NaN    309  39      52       43       60       50   \n",
       "4  5  Charmeleon   Fire     NaN    405  58      64       58       80       65   \n",
       "\n",
       "   Speed  Generation  Legendary  \n",
       "0     45           1      False  \n",
       "1     60           1      False  \n",
       "2     80           1      False  \n",
       "3     65           1      False  \n",
       "4     80           1      False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many rows has our DataFrame?\n",
    "\n",
    "    How many total rows do we have in ``df``?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "721"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 What's the type of index of our DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 721 entries, 0 to 720\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   #           721 non-null    int64 \n",
      " 1   Name        721 non-null    object\n",
      " 2   Type 1      721 non-null    object\n",
      " 3   Type 2      359 non-null    object\n",
      " 4   Total       721 non-null    int64 \n",
      " 5   HP          721 non-null    int64 \n",
      " 6   Attack      721 non-null    int64 \n",
      " 7   Defense     721 non-null    int64 \n",
      " 8   Sp. Atk     721 non-null    int64 \n",
      " 9   Sp. Def     721 non-null    int64 \n",
      " 10  Speed       721 non-null    int64 \n",
      " 11  Generation  721 non-null    int64 \n",
      " 12  Legendary   721 non-null    bool  \n",
      "dtypes: bool(1), int64(9), object(3)\n",
      "memory usage: 68.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How many columns does our DataFrame have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What's the shape of our DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What's the type of the column Name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Name'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Which of the following columns are of a numeric type?\n",
    "\n",
    "    Mark the ones that are of some numeric type (``int``, ``float``, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Select the column ``Defense``\n",
    "\n",
    "    Select the column defense and store it in the variable ``defense_col``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "defense_col = df['Defense']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. What's the type of the variable ``defense_col``?\n",
    "\n",
    "    What's the type of the variable in which you've selected the column Defense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defense_col.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. What's the maximum value of ``Attack``?\n",
    "\n",
    "    Insert the whole number, without decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Attack'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. What's the average value for ``Speed``?\n",
    "\n",
    "    Insert the answer up to 2 decimals. Example, if the value is 84.813799 insert just 84.81."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.71428571428571"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Speed'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mastering DataFrame Mutations with Wine Quality Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Objectives\n",
    "\n",
    "Welcome to the hands-on practice session of the modifying data frame lesson! As you dive deeper into this section, you will have the opportunity to hone your skills in manipulating datasets. In this tutorial, we will be working with the ``wine quality dataset`` which provides insightful information about the Portuguese ``Vinho Verde`` red wine collected in 2009. This dataset contains ``12`` attributes and ``1599`` data points that reflect the physicochemical properties and quality of the wine, giving us a better understanding of consumer preferences.\n",
    "\n",
    "Using the pandas' library, we will load the dataset with the following line of code: ``pd.read_csv(wine_quality_df)`` and inspect it with ``df.info()`` and ``df.describe()``.\n",
    "\n",
    "> ***The dataset used for this project was taken from the publicly available and Open Source [UCL Machine Learning repository](https://archive.ics.uci.edu/ml/datasets/wine+quality).***\n",
    "\n",
    "Before we dive into the manipulation of the dataset, it's important to clean the data to ensure accuracy. We will be using various techniques such as ``df.insert``, ``df.astype``, ``df.columns``, ``df.rename``, and ``df.drop`` to modify the data frame to our desired outcome. By the end of this project, you will be able to confidently manipulate the columns, and rows, and perform operations on the dataset with ease.\n",
    "\n",
    "It's time to put your newly acquired skills to the test! The next page contains questions that will require you to carefully consider your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, let's kick off our analysis by performing some basic activities on our data. This will give us a better understanding of the dataset and allow us to uncover hidden insights. Remember, the first step to gaining knowledge is to understand the data we are working with, so let's get started! To ensure the integrity of our original data set, it's a best practice to work with a copy of the data frame when performing data manipulation. By creating a copy, we can freely experiment with various techniques and make modifications without affecting the original data.\n",
    "\n",
    "```py\n",
    "df = wine_quality_df.copy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_quality_df = pd.read_csv('winequality-red.csv', sep= ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_quality_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "wine_quality_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_quality_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure the integrity of our original data set, it's a best practice to work with a copy of the data frame when performing data manipulation. By creating a copy, we can freely experiment with various techniques and make modifications without affecting the original data. This way, we can have peace of mind knowing that the original data set remains untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wine_quality_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What is median wine quality?\n",
    "\n",
    "    Enter the answer to 1 decimal point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row and Column modification\n",
    "\n",
    "This section contains a jupyter lab activity based on row and column modification. Please launch the notebook on the right side of the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Rename dataframe columns to appropriate format\n",
    "\n",
    "    Rename the columns to have underscore instead of space. For example old name: ``fixed acidity`` to the new name: ``fixed_acidity``. Skip single-word columns. Set ``inplace=True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'fixed acidity':'fixed_acidity', \n",
    "                   'volatile acidity':'volatile_acidity',\n",
    "                   'citric acid':'citric_acid',\n",
    "                   'residual sugar':'residual_sugar',\n",
    "                   'free sulfur dioxide':'free_sulfur_dioxide',\n",
    "                   'total sulfur dioxide':'total_sulfur_dioxide'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Drop the first and last row\n",
    "\n",
    "    Perform the modification and store it in a new variable: ``df_first_last``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_last = df.drop([df.index[0], df.index[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_last = df.drop(df.iloc[[0,-1]].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.068</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99651</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1597 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "5               7.4             0.660         0.00             1.8      0.075   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1593            6.8             0.620         0.08             1.9      0.068   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "\n",
       "      free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "5                    13.0                  40.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1593                 28.0                  38.0  0.99651  3.42       0.82   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "\n",
       "      alcohol  quality  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "5         9.4        5  \n",
       "...       ...      ...  \n",
       "1593      9.5        6  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "\n",
       "[1597 rows x 12 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first_last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Remove maximum total sulfur dioxide from dataset\n",
    "\n",
    "    Locate and remove the row with the maximum value for ``total_sulfur_dioxide`` and store it in a new variable: ``df_drop``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
